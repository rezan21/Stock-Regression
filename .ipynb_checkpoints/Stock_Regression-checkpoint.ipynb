{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "zsAE77B4tH0V",
    "outputId": "2b1e360b-7947-4e42-dbff-2126c05f2c6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "sep = \"-*-*-\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # disable GPU\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "\n",
    "# visuals.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# processing / validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# keras/tf\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "print(tf.__version__)\n",
    "\n",
    "# models\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# constant seed for reproducibility\n",
    "SEED = 111 \n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# cpu workers\n",
    "WORKERS = 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opDdskO6tH0n"
   },
   "outputs": [],
   "source": [
    "def fetch_data(tickers, days, years):\n",
    "\n",
    "    df_raw = pd.DataFrame() \n",
    "    attempt = 0\n",
    "    drop = []\n",
    "    while len(tickers) != 0 and attempt <= 5:\n",
    "        tickers = [j for j in tickers if j not in drop] \n",
    "        for i in range(len(tickers)):\n",
    "            try:\n",
    "                temp = web.get_data_yahoo(tickers[i],datetime.date.today() - datetime.timedelta(DAYS * YEARS), # reduce delta\n",
    "                                          datetime.date.today())\n",
    "\n",
    "                temp.dropna(inplace = True)\n",
    "                df_raw[tickers[i]] = temp[\"Adj Close\"]\n",
    "                drop.append(tickers[i])       \n",
    "            except:\n",
    "                print(tickers[i],\" :failed to fetch data...retrying\")\n",
    "                continue\n",
    "        attempt+=1\n",
    "       \n",
    "    # missing values\n",
    "    # BTC market is open all the time whereas Stock and Index markets are closed on weekends.\n",
    "    # drop missing values caused by this behvaiour\n",
    "    print(\"Missing Values:\")\n",
    "    print(df_raw.isnull().sum())\n",
    "    df = df_raw.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def process_clf_data(target, seq_len, period, features_type, df):\n",
    "    df_pct = pd.DataFrame() # blank dataframe\n",
    "\n",
    "\n",
    "    if features_type==\"since\": # changes since previous days\n",
    "        for col in df.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_snc_[t-{i}]\"] = df[col].pct_change(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    \n",
    "    elif features_type==\"shifted\": # shifted changes of previous days\n",
    "        for col in df.columns:\n",
    "            if col != target: # without target's pct_change\n",
    "                df_pct[col] = df[col].pct_change(1)\n",
    "        df_pct.dropna(inplace=True)\n",
    "        \n",
    "        # shifted previous\n",
    "        for col in df_pct.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_sht_[t-{i}]\"] = df_pct[col].shift(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"features_type can be either 'since' or 'shifted'.\")\n",
    "\n",
    "\n",
    "    df_pct[f\"{target}_price_[t]\"] = df[target] # price [t]\n",
    "\n",
    "    # labeling\n",
    "    df_pct[f\"{target}_Future\"] = df[target].shift(-period) # future price [t + perid]\n",
    "    \n",
    "    warnings = 0\n",
    "    def classify(x):\n",
    "#         print(warnings)\n",
    "        if x[f\"{target}_Future\"] >= x[f\"{target}_price_[t]\"]:\n",
    "            return 1\n",
    "        elif x[f\"{target}_Future\"] < x[f\"{target}_price_[t]\"]:\n",
    "            return 0\n",
    "        else:\n",
    "            nonlocal warnings\n",
    "            warnings += 1\n",
    "            return None\n",
    "    \n",
    "    df_pct[f\"{target}_Future\"] = df_pct.apply(classify, axis=1) # classify\n",
    "\n",
    "\n",
    "    if warnings > 1:\n",
    "        raise ValueError(\"More than 1 NaN in classifying.\")\n",
    "        \n",
    "    \n",
    "    df_pct.dropna(inplace=True)\n",
    "    if df_pct.isnull().any().any():\n",
    "        raise ValueError(\"null values exist\")\n",
    "        \n",
    "    return df_pct\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def process_reg_data(target, seq_len, period, features_type, df):\n",
    "    df_pct = pd.DataFrame() # blank dataframe\n",
    "\n",
    "\n",
    "    if features_type==\"since\": # changes since previous days\n",
    "        for col in df.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_snc_[t-{i}]\"] = df[col].pct_change(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    \n",
    "    elif features_type==\"shifted\": # shifted changes of previous days\n",
    "        for col in df.columns:\n",
    "            if col != target: # without target's pct_change\n",
    "                df_pct[col] = df[col].pct_change(1)\n",
    "        df_pct.dropna(inplace=True)\n",
    "        \n",
    "        # shifted previous\n",
    "        for col in df_pct.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_sht_[t-{i}]\"] = df_pct[col].shift(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"features_type can be either 'since' or 'shifted'.\")\n",
    "\n",
    "\n",
    "    df_pct[f\"{target}_price_[t]\"] = df[target] # target's price\n",
    "\n",
    "    # labeling\n",
    "    df_pct[f\"{target}_Future\"] = df[target].shift(-period)\n",
    "\n",
    "    df_pct.dropna(inplace=True)\n",
    "    if df_pct.isnull().any().any():\n",
    "        raise ValueError(\"null values exist\")\n",
    "        \n",
    "    return df_pct\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def split_data(forward_test, scaling, split_size, proc_data):\n",
    "    \n",
    "    # train/test & faeture/label split\n",
    "    if forward_test==True:\n",
    "    #     forward test (recommended)\n",
    "        nth_prcntile = int(len(proc_data)*split_size)\n",
    "        test_df = proc_data.iloc[nth_prcntile:,:]\n",
    "        \n",
    "        train_df = proc_data.drop(test_df.index)\n",
    "        train_df = train_df.sample(frac=1, random_state=SEED) # shuffle train dataset\n",
    "\n",
    "        # features\n",
    "        X_train = train_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "        X_test = test_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "\n",
    "        # labels\n",
    "        y_train = train_df[f\"{TARGET}_Future\"].values\n",
    "        y_test = test_df[f\"{TARGET}_Future\"].values\n",
    "        \n",
    "    elif forward_test==False:\n",
    "        proc_data = proc_data.sample(frac=(1), random_state=SEED) # shuffle all data\n",
    "        test_df = proc_data.sample(frac=(1-split_size), random_state=SEED) # sample test dataset\n",
    "        train_df = proc_data.drop(test_df.index)\n",
    "\n",
    "        # features\n",
    "        X_train = train_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "        X_test = test_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "\n",
    "        # labels\n",
    "        y_train = train_df[f\"{TARGET}_Future\"].values\n",
    "        y_test = test_df[f\"{TARGET}_Future\"].values\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"forward_test must be boolean.\")\n",
    "\n",
    "\n",
    "    # scaling\n",
    "    if scaling==\"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        x_test_df = pd.DataFrame(X_test, columns=proc_data.drop(f\"{TARGET}_Future\", axis=1).columns, index=test_df.index)\n",
    "        y_test_df = pd.DataFrame(y_test, columns=[f\"{TARGET}_Future\"], index=test_df.index)\n",
    "        test_df = pd.concat([x_test_df, y_test_df], axis=1)\n",
    "        \n",
    "    elif scaling==\"standard\":\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        x_test_df = pd.DataFrame(X_test, columns=proc_data.drop(f\"{TARGET}_Future\", axis=1).columns, index=test_df.index)\n",
    "        y_test_df = pd.DataFrame(y_test, columns=[f\"{TARGET}_Future\"], index=test_df.index)\n",
    "        test_df = pd.concat([x_test_df, y_test_df], axis=1)\n",
    "        \n",
    "    elif scaling==\"none\":\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"scaling can be either 'minmax', 'standard' or 'none'.\")\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, test_df\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def predict_sample(features_serie, model):\n",
    "    features = np.array(features_serie).reshape(1,-1)\n",
    "    pred = model.predict(features)[0]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "4jatVTodtH0w",
    "outputId": "a120d5ab-ea34-4876-adf5-3064ce1b431d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "MSFT    0\n",
      "AAPL    0\n",
      "AMZN    0\n",
      "FB      0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>FB</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-04-14</th>\n",
       "      <td>37.555172</td>\n",
       "      <td>116.228790</td>\n",
       "      <td>385.109985</td>\n",
       "      <td>83.519997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-15</th>\n",
       "      <td>38.105190</td>\n",
       "      <td>116.670502</td>\n",
       "      <td>383.450012</td>\n",
       "      <td>82.709999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-16</th>\n",
       "      <td>38.015030</td>\n",
       "      <td>116.109131</td>\n",
       "      <td>386.040009</td>\n",
       "      <td>82.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-17</th>\n",
       "      <td>37.528114</td>\n",
       "      <td>114.802368</td>\n",
       "      <td>375.559998</td>\n",
       "      <td>80.779999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-20</th>\n",
       "      <td>38.691284</td>\n",
       "      <td>117.425117</td>\n",
       "      <td>389.510010</td>\n",
       "      <td>83.089996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>153.830002</td>\n",
       "      <td>241.410004</td>\n",
       "      <td>1906.589966</td>\n",
       "      <td>154.179993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>165.270004</td>\n",
       "      <td>262.470001</td>\n",
       "      <td>1997.589966</td>\n",
       "      <td>165.550003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>163.490005</td>\n",
       "      <td>259.429993</td>\n",
       "      <td>2011.599976</td>\n",
       "      <td>168.830002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>165.130005</td>\n",
       "      <td>266.070007</td>\n",
       "      <td>2043.000000</td>\n",
       "      <td>174.279999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-09</th>\n",
       "      <td>165.139999</td>\n",
       "      <td>267.989990</td>\n",
       "      <td>2042.760010</td>\n",
       "      <td>175.190002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1258 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MSFT        AAPL         AMZN          FB\n",
       "Date                                                       \n",
       "2015-04-14   37.555172  116.228790   385.109985   83.519997\n",
       "2015-04-15   38.105190  116.670502   383.450012   82.709999\n",
       "2015-04-16   38.015030  116.109131   386.040009   82.309998\n",
       "2015-04-17   37.528114  114.802368   375.559998   80.779999\n",
       "2015-04-20   38.691284  117.425117   389.510010   83.089996\n",
       "...                ...         ...          ...         ...\n",
       "2020-04-03  153.830002  241.410004  1906.589966  154.179993\n",
       "2020-04-06  165.270004  262.470001  1997.589966  165.550003\n",
       "2020-04-07  163.490005  259.429993  2011.599976  168.830002\n",
       "2020-04-08  165.130005  266.070007  2043.000000  174.279999\n",
       "2020-04-09  165.139999  267.989990  2042.760010  175.190002\n",
       "\n",
       "[1258 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tickers = [\"BTC-USD\", \"^DJI\", \"^GSPC\", \"MSFT\", \"AAPL\", \"AMZN\", \"FB\", \"GOOGL\", \"JPM\", \"JNJ\", \"V\", \"MA\", \"INTC\"]\n",
    "TICKERS = [\"MSFT\", \"AAPL\", \"AMZN\", \"FB\"]\n",
    "DAYS = 365\n",
    "YEARS = 5\n",
    "DF = fetch_data(tickers=TICKERS, days=DAYS, years=YEARS)\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "colab_type": "code",
    "id": "xFrHvXXvtH04",
    "outputId": "7ac0f28d-3b94-41c8-8507-718f5e42a9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    377\n",
      "Name: pred_signal, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       175\n",
      "           1       0.54      1.00      0.70       202\n",
      "\n",
      "    accuracy                           0.54       377\n",
      "   macro avg       0.27      0.50      0.35       377\n",
      "weighted avg       0.29      0.54      0.37       377\n",
      "\n",
      "-*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rezanaghshineh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    377\n",
      "Name: pred_signal, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       175\n",
      "           1       0.54      1.00      0.70       202\n",
      "\n",
      "    accuracy                           0.54       377\n",
      "   macro avg       0.27      0.50      0.35       377\n",
      "weighted avg       0.29      0.54      0.37       377\n",
      "\n",
      "-*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rezanaghshineh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    377\n",
      "Name: pred_signal, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       175\n",
      "           1       0.54      1.00      0.70       202\n",
      "\n",
      "    accuracy                           0.54       377\n",
      "   macro avg       0.27      0.50      0.35       377\n",
      "weighted avg       0.29      0.54      0.37       377\n",
      "\n",
      "-*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rezanaghshineh/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    372\n",
      "0      4\n",
      "Name: pred_signal, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.02      0.03       174\n",
      "           1       0.54      1.00      0.70       202\n",
      "\n",
      "    accuracy                           0.54       376\n",
      "   macro avg       0.65      0.51      0.37       376\n",
      "weighted avg       0.64      0.54      0.39       376\n",
      "\n",
      "-*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*-\n"
     ]
    }
   ],
   "source": [
    "# seq 5, per 1\n",
    "for seq in range(1,5):\n",
    "    for per in range(1,2):\n",
    "        TARGET=\"AAPL\"\n",
    "        SEQ_LEN=seq # previous data\n",
    "        PERIOD=per # future data\n",
    "        FEATURES_TYPE=\"since\"\n",
    "        FORWARD_TEST = True\n",
    "        SCALING = \"none\" # none / minmax / standard\n",
    "        SPLIT_SIZE = 0.70 # training size\n",
    "        PATIENCE = 128\n",
    "\n",
    "        processed_data = process_reg_data(target=TARGET, seq_len=SEQ_LEN, period=PERIOD, features_type=FEATURES_TYPE, df=DF)\n",
    "        X_train, X_test, y_train, y_test, test_df = split_data(forward_test=FORWARD_TEST, scaling=SCALING, split_size=SPLIT_SIZE, proc_data=processed_data)\n",
    "#         print(f\"processed shape: {processed_data.shape}\", end=f\"\\n{sep}\\n\")\n",
    "#         print(f\"features: train shape: {X_train.shape} | test Shape: {X_test.shape}\", end=f\"\\n{sep}\\n\")\n",
    "#         print(f\"labels: train shape: {y_train.shape} | test Shape: {y_test.shape}\", end=f\"\\n{sep}\\n\")\n",
    "#         print(f\"X_train Max/Min: {X_train.max()} / {X_train.min()}\")\n",
    "#         test_df.tail()\n",
    "\n",
    "        # model\n",
    "        svmReg = svm.SVR(kernel='linear').fit(X_train, y_train)\n",
    "\n",
    "        eval_df = pd.DataFrame()\n",
    "        eval_df[f\"future_{TARGET}_prediction\"] = test_df.drop(f\"{TARGET}_Future\",axis=1).apply(predict_sample, args=(svmReg,), axis=1)\n",
    "        eval_df = pd.concat([eval_df, processed_data[[f\"{TARGET}_price_[t]\", f\"{TARGET}_Future\"]]], axis=1)\n",
    "        eval_df.columns = ['future_pred', \"todays_price\", \"future_actual\"]\n",
    "        eval_df.dropna(inplace=True)\n",
    "        eval_df[\"actual_signal\"] = eval_df.apply(lambda x: 1 if x[\"future_actual\"] >= x[\"todays_price\"] else 0, axis=1)\n",
    "        eval_df[\"pred_signal\"] = eval_df.apply(lambda x: 1  if x[\"future_pred\"] >= x[\"todays_price\"] else 0, axis=1)\n",
    "        print(eval_df[\"pred_signal\"].value_counts())\n",
    "        print(classification_report(eval_df[\"actual_signal\"], eval_df[\"pred_signal\"]))\n",
    "        print(sep*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.21569038174827\n",
      "0.9852855353613694\n",
      "1    329\n",
      "0     46\n",
      "Name: pred_signal, dtype: int64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.16      0.25       173\n",
      "           1       0.56      0.91      0.69       202\n",
      "\n",
      "    accuracy                           0.56       375\n",
      "   macro avg       0.57      0.53      0.47       375\n",
      "weighted avg       0.57      0.56      0.49       375\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>future_pred</th>\n",
       "      <th>todays_price</th>\n",
       "      <th>future_actual</th>\n",
       "      <th>actual_signal</th>\n",
       "      <th>pred_signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-11</th>\n",
       "      <td>210.658538</td>\n",
       "      <td>210.042480</td>\n",
       "      <td>217.545044</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-12</th>\n",
       "      <td>218.008168</td>\n",
       "      <td>217.545044</td>\n",
       "      <td>212.892654</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-15</th>\n",
       "      <td>213.392742</td>\n",
       "      <td>212.892654</td>\n",
       "      <td>217.584213</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-16</th>\n",
       "      <td>217.849353</td>\n",
       "      <td>217.584213</td>\n",
       "      <td>216.643967</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-17</th>\n",
       "      <td>216.915687</td>\n",
       "      <td>216.643967</td>\n",
       "      <td>211.580200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>244.996602</td>\n",
       "      <td>244.929993</td>\n",
       "      <td>241.410004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>241.580078</td>\n",
       "      <td>241.410004</td>\n",
       "      <td>262.470001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>262.364739</td>\n",
       "      <td>262.470001</td>\n",
       "      <td>259.429993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>259.576327</td>\n",
       "      <td>259.429993</td>\n",
       "      <td>266.070007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-08</th>\n",
       "      <td>266.118291</td>\n",
       "      <td>266.070007</td>\n",
       "      <td>267.989990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            future_pred  todays_price  future_actual  actual_signal  pred_signal\n",
       "Date                                                                            \n",
       "2018-10-11   210.658538    210.042480     217.545044              1            1\n",
       "2018-10-12   218.008168    217.545044     212.892654              0            1\n",
       "2018-10-15   213.392742    212.892654     217.584213              1            1\n",
       "2018-10-16   217.849353    217.584213     216.643967              0            1\n",
       "2018-10-17   216.915687    216.643967     211.580200              0            1\n",
       "...                 ...           ...            ...            ...          ...\n",
       "2020-04-02   244.996602    244.929993     241.410004              0            1\n",
       "2020-04-03   241.580078    241.410004     262.470001              1            1\n",
       "2020-04-06   262.364739    262.470001     259.429993              0            0\n",
       "2020-04-07   259.576327    259.429993     266.070007              1            1\n",
       "2020-04-08   266.118291    266.070007     267.989990              1            1\n",
       "\n",
       "[375 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "svmReg = svm.SVR(kernel='linear').fit(X_train, y_train)\n",
    "svmPreds = svmReg.predict(X_test)\n",
    "print(mean_squared_error(y_test, svmPreds))\n",
    "print(r2_score(y_test, svmPreds))\n",
    "\n",
    "eval_df = pd.DataFrame()\n",
    "eval_df[f\"future_{TARGET}_prediction\"] = test_df.drop(f\"{TARGET}_Future\",axis=1).apply(predict_sample, args=(svmReg,), axis=1)\n",
    "eval_df = pd.concat([eval_df, processed_data[[f\"{TARGET}_price_[t]\", f\"{TARGET}_Future\"]]], axis=1)\n",
    "eval_df.columns = ['future_pred', \"todays_price\", \"future_actual\"]\n",
    "eval_df.dropna(inplace=True)\n",
    "eval_df[\"actual_signal\"] = eval_df.apply(lambda x: 1 if x[\"future_actual\"] >= x[\"todays_price\"] else 0, axis=1)\n",
    "eval_df[\"pred_signal\"] = eval_df.apply(lambda x: 1  if x[\"future_pred\"] >= x[\"todays_price\"] else 0, axis=1)\n",
    "print(eval_df[\"pred_signal\"].value_counts())\n",
    "print(classification_report(eval_df[\"actual_signal\"], eval_df[\"pred_signal\"]))\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svmClf = svm.SVC(kernel='rbf').fit(X_train, y_train)\n",
    "# svmClfPreds = svmClf.predict(X_test)\n",
    "# print(classification_report(y_test, svmClfPreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "U-SkT913tH09",
    "outputId": "dbf888cd-9b0f-4f04-b6e9-39707a6dbf33",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def fit_ann():\n",
    "#     dnnReg = Sequential()\n",
    "\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "\n",
    "#     dnnReg.add(Dense(1))\n",
    "\n",
    "#     dnnReg.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "#     early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE)\n",
    "\n",
    "#     dnnReg.fit(x=X_train, y=y_train, epochs=1000,validation_data=(X_test,y_test),use_multiprocessing=True, workers=WORKERS, callbacks=[early_stop])\n",
    "#     return dnnReg\n",
    "\n",
    "# if False:\n",
    "#     dnnReg = fit_ann()\n",
    "#     pd.DataFrame(dnnReg.history.history).plot()\n",
    "#     dnnPreds = dnnReg.predict(X_test)\n",
    "#     print(sep*5)\n",
    "#     print(mean_squared_error(y_test, dnnPreds))\n",
    "#     print(r2_score(y_test, dnnPreds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot timeseries, SMA, signals\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=test_df.index,\n",
    "#     y=y_test,\n",
    "#     name=f\"Actual\",\n",
    "# #     line_color='#c761ff',\n",
    "#     line=dict(width=2, dash=\"solid\"),\n",
    "#     opacity=0.6\n",
    "#     )\n",
    "# )\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=test_df.index,\n",
    "#     y=svmPreds,\n",
    "#     name=f\"Predicted\",\n",
    "# #     line_color='#c761ff',\n",
    "#     line=dict(width=2, dash=\"dot\"),\n",
    "#     opacity=1\n",
    "#     )\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # fig.update_layout(\n",
    "# #     title=f'{STOCK} Daily Chart',\n",
    "# #     xaxis_title='Date',\n",
    "# #     yaxis_title='Price ($)',\n",
    "# #     template=\"plotly_dark\",\n",
    "# # )\n",
    "\n",
    "\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDDOTo3ZtH1e"
   },
   "outputs": [],
   "source": [
    "# # models:\n",
    "\n",
    "# gboostReg = GradientBoostingRegressor(n_estimators=10000, learning_rate=0.01, max_depth=1,  loss='ls', random_state=SEED).fit(X_train, y_train)\n",
    "# gboostPredds = gboostReg.predict(X_test)\n",
    "# print(mean_squared_error(y_test, gboostPredds))\n",
    "# print(r2_score(y_test, gboostPredds))\n",
    "\n",
    "\n",
    "# dtReg = tree.DecisionTreeRegressor(random_state=SEED).fit(X_train, y_train)\n",
    "# dtPredds = dtReg.predict(X_test)\n",
    "# print(mean_squared_error(y_test, dtPredds))\n",
    "# print(r2_score(y_test, dtPredds))\n",
    "\n",
    "# ensReg = VotingRegressor(estimators=\n",
    "#                          [\n",
    "#                              ('svmReg', svmReg),\n",
    "#                              ('gboost', gboostReg),\n",
    "#                              ('dtReg', dtReg)\n",
    "#                          ]\n",
    "#                         ).fit(X_train, y_train)\n",
    "# print(mean_squared_error(y_test, ensReg.predict(X_test)))\n",
    "# print(r2_score(y_test, ensReg.predict(X_test)))\n",
    "\n",
    "###################################################################################################################\n",
    "# # visualisations:\n",
    "\n",
    "# # correlation heatmap\n",
    "# # plt.figure(figsize=(15,7))\n",
    "# corr = df.corr()\n",
    "# mask = np.zeros_like(corr)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# with sns.axes_style(\"white\"):\n",
    "#     ax1 = sns.heatmap(corr, mask=mask, square=False,cmap=\"coolwarm\").set_title(\"Percent Change Correlation Heatmap\")       \n",
    "# ###\n",
    "\n",
    "\n",
    "# # distributions\n",
    "# fig = ff.create_distplot([df.pct_change().dropna()[c] for c in df.pct_change().columns], df.pct_change().columns, show_rug=False, show_hist=False)\n",
    "# fig.update_layout(\n",
    "#     title=f'Daily Return Distribution')\n",
    "# fig.show()\n",
    "# ###\n",
    "\n",
    "\n",
    "# # prices subplots\n",
    "# fig = make_subplots(rows=df.shape[1], cols=1, start_cell=\"bottom-left\",     subplot_titles=df.columns,shared_xaxes=True)\n",
    "\n",
    "# i, j = 1, 1\n",
    "# for col in df.columns:\n",
    "#     fig.add_trace(go.Scatter(x=df.index, y=df[col],name=col), row=i, col=1)\n",
    "#     i += 1\n",
    "# #     if j != 4: i += 1\n",
    "# #     else:\n",
    "# #         i += 1\n",
    "# #         j = 1\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=f' Daily Chart',\n",
    "#     xaxis_title='Date',\n",
    "#     yaxis_title='Price ($)',\n",
    "# #     xaxis=dict(position=1)\n",
    "# #     template=\"plotly_dark\",\n",
    "# )\n",
    "# fig.update_layout(\n",
    "#     autosize=True,\n",
    "# #      width=1500,\n",
    "#     height=2000,\n",
    "#     margin=dict(\n",
    "#         l=50,\n",
    "#         r=50,\n",
    "#         b=100,\n",
    "#         t=100,\n",
    "#         pad=4\n",
    "#     ),\n",
    "# #     paper_bgcolor=\"LightSteelBlue\",\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Stock_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
