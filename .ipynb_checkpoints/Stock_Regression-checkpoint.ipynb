{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "zsAE77B4tH0V",
    "outputId": "2b1e360b-7947-4e42-dbff-2126c05f2c6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rezanaghshineh/opt/anaconda3/lib/python3.7/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "sep = \"-*-*-\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # disable GPU\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "\n",
    "# visuals.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# processing / validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# keras/tf\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "print(\"tensorflow version: \", tf.__version__)\n",
    "\n",
    "# models\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score # reg metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_auc_score,\\\n",
    "accuracy_score, precision_score, average_precision_score, balanced_accuracy_score,\\\n",
    "precision_recall_fscore_support# clf metrics\n",
    "\n",
    "# constant seed for reproducibility\n",
    "SEED = 111 \n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# cpu workers\n",
    "WORKERS = 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opDdskO6tH0n"
   },
   "outputs": [],
   "source": [
    "def fetch_data_since(tickers, days, years):\n",
    "\n",
    "    df_raw = pd.DataFrame() \n",
    "    attempt = 0\n",
    "    drop = []\n",
    "    while len(tickers) != 0 and attempt <= 5:\n",
    "        tickers = [j for j in tickers if j not in drop] \n",
    "        for i in range(len(tickers)):\n",
    "            try:\n",
    "                temp = web.get_data_yahoo(tickers[i],\n",
    "                                          datetime.date.today() - datetime.timedelta(days * years), # since delta\n",
    "                                          datetime.date.today()) # until today \n",
    "\n",
    "                temp.dropna(inplace = True)\n",
    "                df_raw[tickers[i]] = temp[\"Adj Close\"]\n",
    "                drop.append(tickers[i])       \n",
    "            except:\n",
    "                print(tickers[i],\" :failed to fetch data...retrying\")\n",
    "                continue\n",
    "        attempt+=1\n",
    "       \n",
    "    # missing values\n",
    "    print(\"Missing Values:\")\n",
    "    print(df_raw.isnull().sum())\n",
    "    df = df_raw.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def fetch_data_from_to(tickers, _from, to):\n",
    "\n",
    "    df_raw = pd.DataFrame() \n",
    "    attempt = 0\n",
    "    drop = []\n",
    "    while len(tickers) != 0 and attempt <= 5:\n",
    "        tickers = [j for j in tickers if j not in drop] \n",
    "        for i in range(len(tickers)):\n",
    "            try:\n",
    "                temp = web.get_data_yahoo(tickers[i], _from, to ) # specified range\n",
    "\n",
    "                temp.dropna(inplace = True)\n",
    "                df_raw[tickers[i]] = temp[\"Adj Close\"]\n",
    "                drop.append(tickers[i])       \n",
    "            except:\n",
    "                print(tickers[i],\" :failed to fetch data...retrying\")\n",
    "                continue\n",
    "        attempt+=1\n",
    "       \n",
    "    # missing values\n",
    "    print(\"Missing Values:\")\n",
    "    print(df_raw.isnull().sum())\n",
    "    df = df_raw.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def process_clf_data(target, seq_len, period, features_type, df):\n",
    "    print(f\"\\n{sep*10}\\nClassification(!) Processing\\n{sep*10}\")\n",
    "    df_pct = pd.DataFrame() # blank dataframe\n",
    "\n",
    "\n",
    "    if features_type==\"since\": # changes since previous days\n",
    "        for col in df.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_snc_[t-{i}]\"] = df[col].pct_change(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    \n",
    "    elif features_type==\"shifted\": # shifted changes of previous days\n",
    "        for col in df.columns:\n",
    "#             if col != target: # without target's pct_change\n",
    "            df_pct[col] = df[col].pct_change(1)\n",
    "        df_pct.dropna(inplace=True)\n",
    "        \n",
    "        # shifted previous\n",
    "        for col in df_pct.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_sht_[t-{i}]\"] = df_pct[col].shift(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"features_type can be either 'since' or 'shifted'.\")\n",
    "\n",
    "\n",
    "    df_pct[f\"{target}_price_[t]\"] = df[target] # price [t]\n",
    "\n",
    "    # labeling\n",
    "    df_pct[f\"{target}_Future\"] = df[target].shift(-period) # future price [t + perid]\n",
    "    \n",
    "    warnings = 0\n",
    "    def classify(x):\n",
    "        if x[f\"{target}_Future\"] >= x[f\"{target}_price_[t]\"]:\n",
    "            return 1\n",
    "        elif x[f\"{target}_Future\"] < x[f\"{target}_price_[t]\"]:\n",
    "            return 0\n",
    "        else:\n",
    "            nonlocal warnings\n",
    "            warnings += 1\n",
    "            return None\n",
    "    \n",
    "    df_pct[f\"{target}_Future\"] = df_pct.apply(classify, axis=1) # classify\n",
    "\n",
    "\n",
    "    if warnings > 1:\n",
    "        raise ValueError(\"More than 1 NaN in classifying.\")\n",
    "        \n",
    "    \n",
    "    df_pct.dropna(inplace=True)\n",
    "    if df_pct.isnull().any().any():\n",
    "        raise ValueError(\"null values exist\")\n",
    "        \n",
    "    return df_pct\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def process_reg_data(target, seq_len, period, features_type, df):\n",
    "    print(f\"\\n{sep*10}\\nRegression Processing\\n{sep*10}\")\n",
    "    df_pct = pd.DataFrame() # blank dataframe\n",
    "\n",
    "\n",
    "    if features_type==\"since\": # changes since previous days\n",
    "        for col in df.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_snc_[t-{i}]\"] = df[col].pct_change(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    \n",
    "    elif features_type==\"shifted\": # shifted changes of previous days\n",
    "        for col in df.columns:\n",
    "#             if col != target: # without target's pct_change\n",
    "            df_pct[col] = df[col].pct_change(1)\n",
    "        df_pct.dropna(inplace=True)\n",
    "        \n",
    "        # shifted previous\n",
    "        for col in df_pct.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_sht_[t-{i}]\"] = df_pct[col].shift(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"features_type can be either 'since' or 'shifted'.\")\n",
    "\n",
    "\n",
    "    df_pct[f\"{target}_price_[t]\"] = df[target] # target's price\n",
    "\n",
    "    # labeling\n",
    "    df_pct[f\"{target}_Future\"] = df[target].shift(-period)\n",
    "\n",
    "    df_pct.dropna(inplace=True)\n",
    "    if df_pct.isnull().any().any():\n",
    "        raise ValueError(\"null values exist\")\n",
    "        \n",
    "    return df_pct\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def split_data(forward_test, scaling, split_size, proc_data):\n",
    "    \n",
    "    # train/test & faeture/label split\n",
    "    if forward_test==True:\n",
    "    #     forward test (recommended)\n",
    "        nth_prcntile = int(len(proc_data)*split_size)\n",
    "        test_df = proc_data.iloc[nth_prcntile:,:]\n",
    "        \n",
    "        train_df = proc_data.drop(test_df.index)\n",
    "        train_df = train_df.sample(frac=1, random_state=SEED) # shuffle train dataset\n",
    "\n",
    "        # features\n",
    "        X_train = train_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "        X_test = test_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "\n",
    "        # labels\n",
    "        y_train = train_df[f\"{TARGET}_Future\"].values\n",
    "        y_test = test_df[f\"{TARGET}_Future\"].values\n",
    "        \n",
    "    elif forward_test==False:\n",
    "        proc_data = proc_data.sample(frac=(1), random_state=SEED) # shuffle all data\n",
    "        test_df = proc_data.sample(frac=(1-split_size), random_state=SEED) # sample test dataset\n",
    "        train_df = proc_data.drop(test_df.index)\n",
    "\n",
    "        # features\n",
    "        X_train = train_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "        X_test = test_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "\n",
    "        # labels\n",
    "        y_train = train_df[f\"{TARGET}_Future\"].values\n",
    "        y_test = test_df[f\"{TARGET}_Future\"].values\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"forward_test must be boolean.\")\n",
    "\n",
    "\n",
    "    # scaling\n",
    "    if scaling==\"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        x_test_df = pd.DataFrame(X_test, columns=proc_data.drop(f\"{TARGET}_Future\", axis=1).columns, index=test_df.index)\n",
    "        y_test_df = pd.DataFrame(y_test, columns=[f\"{TARGET}_Future\"], index=test_df.index)\n",
    "        test_df = pd.concat([x_test_df, y_test_df], axis=1)\n",
    "        \n",
    "    elif scaling==\"standard\":\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        x_test_df = pd.DataFrame(X_test, columns=proc_data.drop(f\"{TARGET}_Future\", axis=1).columns, index=test_df.index)\n",
    "        y_test_df = pd.DataFrame(y_test, columns=[f\"{TARGET}_Future\"], index=test_df.index)\n",
    "        test_df = pd.concat([x_test_df, y_test_df], axis=1)\n",
    "        \n",
    "    elif scaling==\"none\":\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"scaling can be either 'minmax', 'standard' or 'none'.\")\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, test_df\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "# tf neural\n",
    "def fit_ann(PATIENCE=32, epochs=1000, nodes=100, hls=9):\n",
    "    dnnReg = Sequential()\n",
    "    \n",
    "    for l in range(hls):\n",
    "        dnnReg.add(Dense(nodes, activation=\"relu\"))\n",
    "#         dnnReg.add(Dropout(0.2))\n",
    "    dnnReg.add(Dense(1))\n",
    "\n",
    "    dnnReg.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE)\n",
    "\n",
    "    dnnReg.fit(x=X_train, y=y_train, epochs=epochs, validation_data=(X_test,y_test), use_multiprocessing=True, workers=WORKERS, callbacks=[early_stop])\n",
    "    return dnnReg\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def predict_sample(features_serie, model):\n",
    "    features = np.array(features_serie).reshape(1,-1)\n",
    "    pred = model.predict(features)[0]\n",
    "    return pred\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def open_pos(qnt, open_price, pos_type):\n",
    "    pos = {\"qnt\":qnt, \"open_price\":open_price, \"cost\":qnt * open_price, \"type\":pos_type}\n",
    "    return pos\n",
    "\n",
    "def get_profit(pos, close_price):\n",
    "    profit = (pos[\"qnt\"] * close_price) - (pos[\"qnt\"] * pos[\"open_price\"]) \n",
    "    if pos[\"type\"] == \"SHORT\":\n",
    "        profit = -profit\n",
    "    return profit\n",
    "    \n",
    "def return_profit(x):\n",
    "    global BALANCE\n",
    "    global pos\n",
    "    \n",
    "    DATE = x.name.date()\n",
    "    PRICE = x[\"todays_price\"]\n",
    "    \n",
    "    # close position\n",
    "    if pos:\n",
    "        profit = get_profit(pos, close_price=PRICE)\n",
    "        BALANCE += pos[\"cost\"] + profit # remaining\n",
    "                \n",
    "#         if pos[\"type\"] == \"SHORT\":\n",
    "#             print(f\"Closed {pos['qnt']} Short at {round(PRICE,6)} on {DATE} | -> {profit}\")\n",
    "            \n",
    "#         if pos[\"type\"] == \"LONG\":\n",
    "#             print(f\"Closed {pos['qnt']} Long at {round(PRICE,6)} on {DATE} | -> {profit}\")\n",
    "        \n",
    "        pos = None # remove position\n",
    "        \n",
    "    # LONG    \n",
    "    if x[\"pred_signal\"] == 1 and not pos and BALANCE > PRICE:\n",
    "        qnt = math.floor(BALANCE / PRICE)\n",
    "        pos = open_pos(qnt=qnt, open_price=PRICE, pos_type=\"LONG\")\n",
    "        BALANCE -= pos[\"cost\"]\n",
    "#         print(f\"LONG {pos['qnt']} at {round(PRICE,6)} on {DATE}\")\n",
    "\n",
    " \n",
    "    # SHORT\n",
    "    if ALLOW_SHORTS:\n",
    "        if x[\"pred_signal\"] == 0 and not pos and BALANCE > PRICE:\n",
    "            qnt = math.floor(BALANCE / PRICE)\n",
    "            pos = open_pos(qnt=qnt, open_price=PRICE, pos_type=\"SHORT\")\n",
    "            BALANCE -= pos[\"cost\"]\n",
    "#             print(f\"SHORT {pos['qnt']} at {round(PRICE,6)} on {DATE}\")\n",
    "\n",
    "    try:\n",
    "        return profit\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def get_balance(x):\n",
    "    global _balance\n",
    "    global first_iter\n",
    "    \n",
    "    if first_iter:\n",
    "        first_iter = False\n",
    "        return _balance\n",
    "    else:\n",
    "        _balance += x[\"P&L\"]\n",
    "        return _balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "4jatVTodtH0w",
    "outputId": "a120d5ab-ea34-4876-adf5-3064ce1b431d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "^DJI     0\n",
      "^GSPC    0\n",
      "MSFT     0\n",
      "AAPL     0\n",
      "AMZN     0\n",
      "GOOGL    0\n",
      "JPM      0\n",
      "JNJ      0\n",
      "V        0\n",
      "MA       0\n",
      "INTC     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^DJI</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>JPM</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>V</th>\n",
       "      <th>MA</th>\n",
       "      <th>INTC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>28515.449219</td>\n",
       "      <td>3223.379883</td>\n",
       "      <td>156.951309</td>\n",
       "      <td>283.596924</td>\n",
       "      <td>1789.209961</td>\n",
       "      <td>1344.430054</td>\n",
       "      <td>135.296478</td>\n",
       "      <td>145.005341</td>\n",
       "      <td>187.298752</td>\n",
       "      <td>296.624969</td>\n",
       "      <td>59.118862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>28621.390625</td>\n",
       "      <td>3239.909912</td>\n",
       "      <td>158.237793</td>\n",
       "      <td>289.223602</td>\n",
       "      <td>1868.770020</td>\n",
       "      <td>1362.469971</td>\n",
       "      <td>136.732239</td>\n",
       "      <td>144.905991</td>\n",
       "      <td>188.886444</td>\n",
       "      <td>298.340027</td>\n",
       "      <td>59.526852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>28645.259766</td>\n",
       "      <td>3240.020020</td>\n",
       "      <td>158.527008</td>\n",
       "      <td>289.113831</td>\n",
       "      <td>1869.800049</td>\n",
       "      <td>1354.640015</td>\n",
       "      <td>136.830582</td>\n",
       "      <td>144.826492</td>\n",
       "      <td>189.116104</td>\n",
       "      <td>299.875580</td>\n",
       "      <td>59.785580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>28462.140625</td>\n",
       "      <td>3221.290039</td>\n",
       "      <td>157.160736</td>\n",
       "      <td>290.829773</td>\n",
       "      <td>1846.890015</td>\n",
       "      <td>1339.709961</td>\n",
       "      <td>136.329041</td>\n",
       "      <td>144.379349</td>\n",
       "      <td>187.558365</td>\n",
       "      <td>296.864258</td>\n",
       "      <td>59.327831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>28538.439453</td>\n",
       "      <td>3230.780029</td>\n",
       "      <td>157.270432</td>\n",
       "      <td>292.954712</td>\n",
       "      <td>1847.839966</td>\n",
       "      <td>1339.390015</td>\n",
       "      <td>137.086258</td>\n",
       "      <td>144.945724</td>\n",
       "      <td>187.628250</td>\n",
       "      <td>297.731781</td>\n",
       "      <td>59.556702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ^DJI        ^GSPC        MSFT        AAPL         AMZN        GOOGL         JPM         JNJ           V          MA       INTC\n",
       "Date                                                                                                                                              \n",
       "2019-12-24  28515.449219  3223.379883  156.951309  283.596924  1789.209961  1344.430054  135.296478  145.005341  187.298752  296.624969  59.118862\n",
       "2019-12-26  28621.390625  3239.909912  158.237793  289.223602  1868.770020  1362.469971  136.732239  144.905991  188.886444  298.340027  59.526852\n",
       "2019-12-27  28645.259766  3240.020020  158.527008  289.113831  1869.800049  1354.640015  136.830582  144.826492  189.116104  299.875580  59.785580\n",
       "2019-12-30  28462.140625  3221.290039  157.160736  290.829773  1846.890015  1339.709961  136.329041  144.379349  187.558365  296.864258  59.327831\n",
       "2019-12-31  28538.439453  3230.780029  157.270432  292.954712  1847.839966  1339.390015  137.086258  144.945724  187.628250  297.731781  59.556702"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TICKERS = [\"^DJI\", \"^GSPC\", \"MSFT\", \"AAPL\", \"AMZN\", \"GOOGL\", \"JPM\", \"JNJ\", \"V\", \"MA\", \"INTC\"]\n",
    "# TICKERS = [\"MSFT\", \"AAPL\", \"AMZN\"]\n",
    "\n",
    "# DAYS = 365\n",
    "# YEARS = 3\n",
    "# DF = fetch_data_since(tickers=TICKERS, days=DAYS, years=YEARS)\n",
    "\n",
    "FROM = '2015'\n",
    "TO = '2020' # excld.\n",
    "DF = fetch_data_from_to(tickers=TICKERS, _from=FROM, to=TO)\n",
    "\n",
    "DF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "colab_type": "code",
    "id": "xFrHvXXvtH04",
    "outputId": "7ac0f28d-3b94-41c8-8507-718f5e42a9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*-\n",
      "Regression Processing\n",
      "-*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*-\n",
      "processed shape: (1246, 123)\n",
      "-*-*-\n",
      "test_df shape: (623, 123)\n",
      "-*-*-\n",
      "features: train shape: (623, 122) | test Shape: (623, 122)\n",
      "-*-*-\n",
      "labels: train shape: (623,) | test Shape: (623,)\n",
      "-*-*-\n",
      "X_train Max/Min: 94.840576171875 / -0.09253331576226898\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^DJI</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GOOGL</th>\n",
       "      <th>JPM</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>V</th>\n",
       "      <th>MA</th>\n",
       "      <th>INTC</th>\n",
       "      <th>^DJI_sht_[t-1]</th>\n",
       "      <th>^DJI_sht_[t-2]</th>\n",
       "      <th>^DJI_sht_[t-3]</th>\n",
       "      <th>^DJI_sht_[t-4]</th>\n",
       "      <th>^DJI_sht_[t-5]</th>\n",
       "      <th>^DJI_sht_[t-6]</th>\n",
       "      <th>^DJI_sht_[t-7]</th>\n",
       "      <th>^DJI_sht_[t-8]</th>\n",
       "      <th>^DJI_sht_[t-9]</th>\n",
       "      <th>^DJI_sht_[t-10]</th>\n",
       "      <th>^GSPC_sht_[t-1]</th>\n",
       "      <th>^GSPC_sht_[t-2]</th>\n",
       "      <th>^GSPC_sht_[t-3]</th>\n",
       "      <th>^GSPC_sht_[t-4]</th>\n",
       "      <th>^GSPC_sht_[t-5]</th>\n",
       "      <th>^GSPC_sht_[t-6]</th>\n",
       "      <th>^GSPC_sht_[t-7]</th>\n",
       "      <th>^GSPC_sht_[t-8]</th>\n",
       "      <th>^GSPC_sht_[t-9]</th>\n",
       "      <th>^GSPC_sht_[t-10]</th>\n",
       "      <th>MSFT_sht_[t-1]</th>\n",
       "      <th>MSFT_sht_[t-2]</th>\n",
       "      <th>MSFT_sht_[t-3]</th>\n",
       "      <th>MSFT_sht_[t-4]</th>\n",
       "      <th>MSFT_sht_[t-5]</th>\n",
       "      <th>MSFT_sht_[t-6]</th>\n",
       "      <th>MSFT_sht_[t-7]</th>\n",
       "      <th>MSFT_sht_[t-8]</th>\n",
       "      <th>MSFT_sht_[t-9]</th>\n",
       "      <th>MSFT_sht_[t-10]</th>\n",
       "      <th>AAPL_sht_[t-1]</th>\n",
       "      <th>AAPL_sht_[t-2]</th>\n",
       "      <th>AAPL_sht_[t-3]</th>\n",
       "      <th>AAPL_sht_[t-4]</th>\n",
       "      <th>AAPL_sht_[t-5]</th>\n",
       "      <th>AAPL_sht_[t-6]</th>\n",
       "      <th>AAPL_sht_[t-7]</th>\n",
       "      <th>AAPL_sht_[t-8]</th>\n",
       "      <th>AAPL_sht_[t-9]</th>\n",
       "      <th>AAPL_sht_[t-10]</th>\n",
       "      <th>AMZN_sht_[t-1]</th>\n",
       "      <th>AMZN_sht_[t-2]</th>\n",
       "      <th>AMZN_sht_[t-3]</th>\n",
       "      <th>AMZN_sht_[t-4]</th>\n",
       "      <th>AMZN_sht_[t-5]</th>\n",
       "      <th>AMZN_sht_[t-6]</th>\n",
       "      <th>AMZN_sht_[t-7]</th>\n",
       "      <th>AMZN_sht_[t-8]</th>\n",
       "      <th>AMZN_sht_[t-9]</th>\n",
       "      <th>AMZN_sht_[t-10]</th>\n",
       "      <th>GOOGL_sht_[t-1]</th>\n",
       "      <th>GOOGL_sht_[t-2]</th>\n",
       "      <th>GOOGL_sht_[t-3]</th>\n",
       "      <th>GOOGL_sht_[t-4]</th>\n",
       "      <th>GOOGL_sht_[t-5]</th>\n",
       "      <th>GOOGL_sht_[t-6]</th>\n",
       "      <th>GOOGL_sht_[t-7]</th>\n",
       "      <th>GOOGL_sht_[t-8]</th>\n",
       "      <th>GOOGL_sht_[t-9]</th>\n",
       "      <th>GOOGL_sht_[t-10]</th>\n",
       "      <th>JPM_sht_[t-1]</th>\n",
       "      <th>JPM_sht_[t-2]</th>\n",
       "      <th>JPM_sht_[t-3]</th>\n",
       "      <th>JPM_sht_[t-4]</th>\n",
       "      <th>JPM_sht_[t-5]</th>\n",
       "      <th>JPM_sht_[t-6]</th>\n",
       "      <th>JPM_sht_[t-7]</th>\n",
       "      <th>JPM_sht_[t-8]</th>\n",
       "      <th>JPM_sht_[t-9]</th>\n",
       "      <th>JPM_sht_[t-10]</th>\n",
       "      <th>JNJ_sht_[t-1]</th>\n",
       "      <th>JNJ_sht_[t-2]</th>\n",
       "      <th>JNJ_sht_[t-3]</th>\n",
       "      <th>JNJ_sht_[t-4]</th>\n",
       "      <th>JNJ_sht_[t-5]</th>\n",
       "      <th>JNJ_sht_[t-6]</th>\n",
       "      <th>JNJ_sht_[t-7]</th>\n",
       "      <th>JNJ_sht_[t-8]</th>\n",
       "      <th>JNJ_sht_[t-9]</th>\n",
       "      <th>JNJ_sht_[t-10]</th>\n",
       "      <th>V_sht_[t-1]</th>\n",
       "      <th>V_sht_[t-2]</th>\n",
       "      <th>V_sht_[t-3]</th>\n",
       "      <th>V_sht_[t-4]</th>\n",
       "      <th>V_sht_[t-5]</th>\n",
       "      <th>V_sht_[t-6]</th>\n",
       "      <th>V_sht_[t-7]</th>\n",
       "      <th>V_sht_[t-8]</th>\n",
       "      <th>V_sht_[t-9]</th>\n",
       "      <th>V_sht_[t-10]</th>\n",
       "      <th>MA_sht_[t-1]</th>\n",
       "      <th>MA_sht_[t-2]</th>\n",
       "      <th>MA_sht_[t-3]</th>\n",
       "      <th>MA_sht_[t-4]</th>\n",
       "      <th>MA_sht_[t-5]</th>\n",
       "      <th>MA_sht_[t-6]</th>\n",
       "      <th>MA_sht_[t-7]</th>\n",
       "      <th>MA_sht_[t-8]</th>\n",
       "      <th>MA_sht_[t-9]</th>\n",
       "      <th>MA_sht_[t-10]</th>\n",
       "      <th>INTC_sht_[t-1]</th>\n",
       "      <th>INTC_sht_[t-2]</th>\n",
       "      <th>INTC_sht_[t-3]</th>\n",
       "      <th>INTC_sht_[t-4]</th>\n",
       "      <th>INTC_sht_[t-5]</th>\n",
       "      <th>INTC_sht_[t-6]</th>\n",
       "      <th>INTC_sht_[t-7]</th>\n",
       "      <th>INTC_sht_[t-8]</th>\n",
       "      <th>INTC_sht_[t-9]</th>\n",
       "      <th>INTC_sht_[t-10]</th>\n",
       "      <th>V_price_[t]</th>\n",
       "      <th>V_Future</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>-0.003764</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>-0.003163</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>-0.002570</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>0.013593</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>-0.014000</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>-0.005887</td>\n",
       "      <td>-0.001193</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>-0.004270</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>-0.008767</td>\n",
       "      <td>0.028618</td>\n",
       "      <td>-0.002379</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>-0.002577</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>-0.003630</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>-0.003342</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>-0.003608</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>-0.004614</td>\n",
       "      <td>0.017081</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.006932</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>186.809448</td>\n",
       "      <td>187.298752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>-0.001264</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>-0.004590</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>-0.003483</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>-0.001097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>-0.001520</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>0.013593</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>-0.005887</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>-0.004270</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>-0.008767</td>\n",
       "      <td>0.028618</td>\n",
       "      <td>-0.002379</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>-0.002577</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>-0.003630</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>-0.003342</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>-0.003608</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.017081</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.006932</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>187.298752</td>\n",
       "      <td>188.886444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>0.044467</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>-0.001264</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>0.013593</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.005468</td>\n",
       "      <td>-0.004590</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>-0.004270</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>-0.008767</td>\n",
       "      <td>0.028618</td>\n",
       "      <td>-0.002379</td>\n",
       "      <td>-0.003483</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>-0.002577</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.007072</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>-0.003342</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>-0.001372</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.017081</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.006932</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>188.886444</td>\n",
       "      <td>189.116104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>-0.005747</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>-0.001264</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>0.013593</td>\n",
       "      <td>0.002548</td>\n",
       "      <td>0.044467</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>-0.004590</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>-0.004270</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>0.003154</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>-0.008767</td>\n",
       "      <td>0.028618</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.003483</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>-0.002577</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>-0.003342</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.003461</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.017081</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.006932</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>0.008411</td>\n",
       "      <td>189.116104</td>\n",
       "      <td>187.558365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>-0.006393</td>\n",
       "      <td>-0.005781</td>\n",
       "      <td>-0.008619</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>-0.012253</td>\n",
       "      <td>-0.011021</td>\n",
       "      <td>-0.003665</td>\n",
       "      <td>-0.003087</td>\n",
       "      <td>-0.008237</td>\n",
       "      <td>-0.010042</td>\n",
       "      <td>-0.007657</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.003715</td>\n",
       "      <td>-0.001264</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>-0.000986</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>-0.000195</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.004459</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.007148</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.008418</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>0.013593</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.044467</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>-0.005747</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>-0.004590</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>-0.002199</td>\n",
       "      <td>-0.004270</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>-0.000291</td>\n",
       "      <td>-0.000801</td>\n",
       "      <td>-0.004998</td>\n",
       "      <td>-0.001013</td>\n",
       "      <td>0.006116</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>-0.008767</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.003483</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.004885</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>-0.002577</td>\n",
       "      <td>0.012483</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.008477</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>-0.003342</td>\n",
       "      <td>-0.003866</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.013688</td>\n",
       "      <td>0.005147</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>-0.004354</td>\n",
       "      <td>0.003495</td>\n",
       "      <td>0.009466</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>-0.003233</td>\n",
       "      <td>0.002938</td>\n",
       "      <td>0.013278</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.006901</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.017081</td>\n",
       "      <td>0.013818</td>\n",
       "      <td>-0.002269</td>\n",
       "      <td>-0.006932</td>\n",
       "      <td>-0.001557</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>187.558365</td>\n",
       "      <td>187.628250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ^DJI     ^GSPC      MSFT      AAPL      AMZN     GOOGL       JPM       JNJ         V        MA      INTC  ^DJI_sht_[t-1]  ^DJI_sht_[t-2]  ^DJI_sht_[t-3]  ^DJI_sht_[t-4]  ^DJI_sht_[t-5]  ^DJI_sht_[t-6]  ^DJI_sht_[t-7]  ^DJI_sht_[t-8]  ^DJI_sht_[t-9]  ^DJI_sht_[t-10]  ^GSPC_sht_[t-1]  ^GSPC_sht_[t-2]  ^GSPC_sht_[t-3]  ^GSPC_sht_[t-4]  ^GSPC_sht_[t-5]  ^GSPC_sht_[t-6]  ^GSPC_sht_[t-7]  ^GSPC_sht_[t-8]  ^GSPC_sht_[t-9]  ^GSPC_sht_[t-10]  MSFT_sht_[t-1]  MSFT_sht_[t-2]  MSFT_sht_[t-3]  MSFT_sht_[t-4]  MSFT_sht_[t-5]  MSFT_sht_[t-6]  MSFT_sht_[t-7]  MSFT_sht_[t-8]  MSFT_sht_[t-9]  MSFT_sht_[t-10]  AAPL_sht_[t-1]  AAPL_sht_[t-2]  AAPL_sht_[t-3]  AAPL_sht_[t-4]  AAPL_sht_[t-5]  AAPL_sht_[t-6]  AAPL_sht_[t-7]  AAPL_sht_[t-8]  AAPL_sht_[t-9]  AAPL_sht_[t-10]  AMZN_sht_[t-1]  AMZN_sht_[t-2]  AMZN_sht_[t-3]  AMZN_sht_[t-4]  AMZN_sht_[t-5]  AMZN_sht_[t-6]  AMZN_sht_[t-7]  AMZN_sht_[t-8]  AMZN_sht_[t-9]  AMZN_sht_[t-10]  GOOGL_sht_[t-1]  GOOGL_sht_[t-2]  GOOGL_sht_[t-3]  \\\n",
       "Date                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "2019-12-23  0.003389  0.000866  0.000000  0.016318  0.003638 -0.000437 -0.000291  0.002602 -0.004894 -0.004354  0.004750        0.002753        0.004876       -0.000986        0.001107        0.003572        0.000118        0.007909        0.001061       -0.000999        -0.003764         0.004945         0.004459        -0.000432         0.000335         0.007148         0.000073         0.008575         0.002908        -0.001097         -0.003163        0.010918        0.008680       -0.002069       -0.005401        0.006471        0.008418        0.010152        0.003772       -0.001520        -0.002570       -0.002071        0.001001       -0.002389        0.001965        0.017118        0.013593        0.002548        0.008529        0.005844        -0.014000       -0.003225        0.004624       -0.003703        0.012124        0.004696        0.000347        0.006639        0.005468       -0.005887        -0.001193        -0.003848         0.003351        -0.002199   \n",
       "2019-12-24 -0.001264 -0.000195 -0.000191  0.000951 -0.002114 -0.004590  0.002770 -0.003483  0.002619  0.000706  0.003039        0.003389        0.002753        0.004876       -0.000986        0.001107        0.003572        0.000118        0.007909        0.001061        -0.000999         0.000866         0.004945         0.004459        -0.000432         0.000335         0.007148         0.000073         0.008575         0.002908         -0.001097        0.000000        0.010918        0.008680       -0.002069       -0.005401        0.006471        0.008418        0.010152        0.003772        -0.001520        0.016318       -0.002071        0.001001       -0.002389        0.001965        0.017118        0.013593        0.002548        0.008529         0.005844        0.003638       -0.003225        0.004624       -0.003703        0.012124        0.004696        0.000347        0.006639        0.005468        -0.005887        -0.000437        -0.003848         0.003351   \n",
       "2019-12-26  0.003715  0.005128  0.008197  0.019840  0.044467  0.013418  0.010612 -0.000685  0.008477  0.005782  0.006901       -0.001264        0.003389        0.002753        0.004876       -0.000986        0.001107        0.003572        0.000118        0.007909         0.001061        -0.000195         0.000866         0.004945         0.004459        -0.000432         0.000335         0.007148         0.000073         0.008575          0.002908       -0.000191        0.000000        0.010918        0.008680       -0.002069       -0.005401        0.006471        0.008418        0.010152         0.003772        0.000951        0.016318       -0.002071        0.001001       -0.002389        0.001965        0.017118        0.013593        0.002548         0.008529       -0.002114        0.003638       -0.003225        0.004624       -0.003703        0.012124        0.004696        0.000347        0.006639         0.005468        -0.004590        -0.000437        -0.003848   \n",
       "2019-12-27  0.000834  0.000034  0.001828 -0.000380  0.000551 -0.005747  0.000719 -0.000549  0.001216  0.005147  0.004346        0.003715       -0.001264        0.003389        0.002753        0.004876       -0.000986        0.001107        0.003572        0.000118         0.007909         0.005128        -0.000195         0.000866         0.004945         0.004459        -0.000432         0.000335         0.007148         0.000073          0.008575        0.008197       -0.000191        0.000000        0.010918        0.008680       -0.002069       -0.005401        0.006471        0.008418         0.010152        0.019840        0.000951        0.016318       -0.002071        0.001001       -0.002389        0.001965        0.017118        0.013593         0.002548        0.044467       -0.002114        0.003638       -0.003225        0.004624       -0.003703        0.012124        0.004696        0.000347         0.006639         0.013418        -0.004590        -0.000437   \n",
       "2019-12-30 -0.006393 -0.005781 -0.008619  0.005935 -0.012253 -0.011021 -0.003665 -0.003087 -0.008237 -0.010042 -0.007657        0.000834        0.003715       -0.001264        0.003389        0.002753        0.004876       -0.000986        0.001107        0.003572         0.000118         0.000034         0.005128        -0.000195         0.000866         0.004945         0.004459        -0.000432         0.000335         0.007148          0.000073        0.001828        0.008197       -0.000191        0.000000        0.010918        0.008680       -0.002069       -0.005401        0.006471         0.008418       -0.000380        0.019840        0.000951        0.016318       -0.002071        0.001001       -0.002389        0.001965        0.017118         0.013593        0.000551        0.044467       -0.002114        0.003638       -0.003225        0.004624       -0.003703        0.012124        0.004696         0.000347        -0.005747         0.013418        -0.004590   \n",
       "\n",
       "            GOOGL_sht_[t-4]  GOOGL_sht_[t-5]  GOOGL_sht_[t-6]  GOOGL_sht_[t-7]  GOOGL_sht_[t-8]  GOOGL_sht_[t-9]  GOOGL_sht_[t-10]  JPM_sht_[t-1]  JPM_sht_[t-2]  JPM_sht_[t-3]  JPM_sht_[t-4]  JPM_sht_[t-5]  JPM_sht_[t-6]  JPM_sht_[t-7]  JPM_sht_[t-8]  JPM_sht_[t-9]  JPM_sht_[t-10]  JNJ_sht_[t-1]  JNJ_sht_[t-2]  JNJ_sht_[t-3]  JNJ_sht_[t-4]  JNJ_sht_[t-5]  JNJ_sht_[t-6]  JNJ_sht_[t-7]  JNJ_sht_[t-8]  JNJ_sht_[t-9]  JNJ_sht_[t-10]  V_sht_[t-1]  V_sht_[t-2]  V_sht_[t-3]  V_sht_[t-4]  V_sht_[t-5]  V_sht_[t-6]  V_sht_[t-7]  V_sht_[t-8]  V_sht_[t-9]  V_sht_[t-10]  MA_sht_[t-1]  MA_sht_[t-2]  MA_sht_[t-3]  MA_sht_[t-4]  MA_sht_[t-5]  MA_sht_[t-6]  MA_sht_[t-7]  MA_sht_[t-8]  MA_sht_[t-9]  MA_sht_[t-10]  INTC_sht_[t-1]  INTC_sht_[t-2]  INTC_sht_[t-3]  INTC_sht_[t-4]  INTC_sht_[t-5]  INTC_sht_[t-6]  INTC_sht_[t-7]  INTC_sht_[t-8]  INTC_sht_[t-9]  INTC_sht_[t-10]  V_price_[t]    V_Future  \n",
       "Date                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "2019-12-23        -0.004270         0.010268        -0.001201         0.003154         0.001013        -0.000074          0.002688      -0.000801      -0.004998      -0.001013       0.006116       0.003874      -0.008767       0.028618      -0.002379       0.000670       -0.004665       0.004885       0.015085      -0.002577       0.012483       0.002900       0.000283       0.002554       0.007072      -0.003630        0.000855     0.007827     0.008870    -0.003342    -0.003866     0.005942     0.013688     0.003461    -0.001372    -0.003608      0.004117      0.003495      0.009466     -0.004257     -0.003233      0.002938      0.013278      0.007447      0.004989     -0.001557      -0.004614        0.017081        0.013818       -0.002269       -0.006932       -0.001557        0.004170        0.008411        0.008482        0.001061        -0.004929   186.809448  187.298752  \n",
       "2019-12-24        -0.002199        -0.004270         0.010268        -0.001201         0.003154         0.001013         -0.000074      -0.000291      -0.000801      -0.004998      -0.001013       0.006116       0.003874      -0.008767       0.028618      -0.002379        0.000670       0.002602       0.004885       0.015085      -0.002577       0.012483       0.002900       0.000283       0.002554       0.007072       -0.003630    -0.004894     0.007827     0.008870    -0.003342    -0.003866     0.005942     0.013688     0.003461    -0.001372     -0.003608     -0.004354      0.003495      0.009466     -0.004257     -0.003233      0.002938      0.013278      0.007447      0.004989      -0.001557        0.004750        0.017081        0.013818       -0.002269       -0.006932       -0.001557        0.004170        0.008411        0.008482         0.001061   187.298752  188.886444  \n",
       "2019-12-26         0.003351        -0.002199        -0.004270         0.010268        -0.001201         0.003154          0.001013       0.002770      -0.000291      -0.000801      -0.004998      -0.001013       0.006116       0.003874      -0.008767       0.028618       -0.002379      -0.003483       0.002602       0.004885       0.015085      -0.002577       0.012483       0.002900       0.000283       0.002554        0.007072     0.002619    -0.004894     0.007827     0.008870    -0.003342    -0.003866     0.005942     0.013688     0.003461     -0.001372      0.000706     -0.004354      0.003495      0.009466     -0.004257     -0.003233      0.002938      0.013278      0.007447       0.004989        0.003039        0.004750        0.017081        0.013818       -0.002269       -0.006932       -0.001557        0.004170        0.008411         0.008482   188.886444  189.116104  \n",
       "2019-12-27        -0.003848         0.003351        -0.002199        -0.004270         0.010268        -0.001201          0.003154       0.010612       0.002770      -0.000291      -0.000801      -0.004998      -0.001013       0.006116       0.003874      -0.008767        0.028618      -0.000685      -0.003483       0.002602       0.004885       0.015085      -0.002577       0.012483       0.002900       0.000283        0.002554     0.008477     0.002619    -0.004894     0.007827     0.008870    -0.003342    -0.003866     0.005942     0.013688      0.003461      0.005782      0.000706     -0.004354      0.003495      0.009466     -0.004257     -0.003233      0.002938      0.013278       0.007447        0.006901        0.003039        0.004750        0.017081        0.013818       -0.002269       -0.006932       -0.001557        0.004170         0.008411   189.116104  187.558365  \n",
       "2019-12-30        -0.000437        -0.003848         0.003351        -0.002199        -0.004270         0.010268         -0.001201       0.000719       0.010612       0.002770      -0.000291      -0.000801      -0.004998      -0.001013       0.006116       0.003874       -0.008767      -0.000549      -0.000685      -0.003483       0.002602       0.004885       0.015085      -0.002577       0.012483       0.002900        0.000283     0.001216     0.008477     0.002619    -0.004894     0.007827     0.008870    -0.003342    -0.003866     0.005942      0.013688      0.005147      0.005782      0.000706     -0.004354      0.003495      0.009466     -0.004257     -0.003233      0.002938       0.013278        0.004346        0.006901        0.003039        0.004750        0.017081        0.013818       -0.002269       -0.006932       -0.001557         0.004170   187.558365  187.628250  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data prep.\n",
    "TARGET=\"V\"\n",
    "SEQ_LEN=10 # previous data\n",
    "PERIOD=1 # future data\n",
    "FEATURES_TYPE=\"shifted\"\n",
    "FORWARD_TEST = True\n",
    "SCALING = \"none\" # none / minmax / standard\n",
    "SPLIT_SIZE = 0.5 # training size\n",
    "\n",
    "processed_data = process_reg_data(target=TARGET, seq_len=SEQ_LEN, period=PERIOD, features_type=FEATURES_TYPE, df=DF)\n",
    "X_train, X_test, y_train, y_test, test_df = split_data(forward_test=FORWARD_TEST, scaling=SCALING, split_size=SPLIT_SIZE, proc_data=processed_data)\n",
    "\n",
    "print(f\"processed shape: {processed_data.shape}\", end=f\"\\n{sep}\\n\")\n",
    "print(f\"test_df shape: {test_df.shape}\", end=f\"\\n{sep}\\n\")\n",
    "print(f\"features: train shape: {X_train.shape} | test Shape: {X_test.shape}\", end=f\"\\n{sep}\\n\")\n",
    "print(f\"labels: train shape: {y_train.shape} | test Shape: {y_test.shape}\", end=f\"\\n{sep}\\n\")\n",
    "print(f\"X_train Max/Min: {X_train.max()} / {X_train.min()}\")\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 623 samples\n",
      "Epoch 1/1000\n",
      "623/623 [==============================] - 2s 3ms/sample - loss: 3173.0937 - val_loss: 290.5969\n",
      "Epoch 2/1000\n",
      "623/623 [==============================] - 0s 476us/sample - loss: 157.5400 - val_loss: 3.7198\n",
      "Epoch 3/1000\n",
      "623/623 [==============================] - 0s 466us/sample - loss: 21.2772 - val_loss: 41.1550\n",
      "Epoch 4/1000\n",
      "623/623 [==============================] - 0s 495us/sample - loss: 3.9469 - val_loss: 4.4829\n",
      "Epoch 5/1000\n",
      "623/623 [==============================] - 0s 476us/sample - loss: 1.0741 - val_loss: 3.3065\n",
      "Epoch 6/1000\n",
      "623/623 [==============================] - 0s 476us/sample - loss: 0.9542 - val_loss: 4.3036\n",
      "Epoch 7/1000\n",
      "623/623 [==============================] - 0s 462us/sample - loss: 0.8751 - val_loss: 3.4931\n",
      "Epoch 8/1000\n",
      "623/623 [==============================] - 0s 458us/sample - loss: 0.8612 - val_loss: 3.7356\n",
      "Epoch 9/1000\n",
      "623/623 [==============================] - 0s 595us/sample - loss: 0.8642 - val_loss: 4.3494\n",
      "Epoch 10/1000\n",
      "623/623 [==============================] - 0s 589us/sample - loss: 0.8634 - val_loss: 4.2078\n",
      "Epoch 11/1000\n",
      "623/623 [==============================] - 0s 675us/sample - loss: 0.8906 - val_loss: 3.5683\n",
      "Epoch 12/1000\n",
      "623/623 [==============================] - 0s 662us/sample - loss: 0.8541 - val_loss: 3.3114\n",
      "Epoch 13/1000\n",
      "623/623 [==============================] - 0s 731us/sample - loss: 0.9646 - val_loss: 4.0247\n",
      "Epoch 14/1000\n",
      "623/623 [==============================] - 0s 552us/sample - loss: 0.8737 - val_loss: 3.3979\n",
      "Epoch 15/1000\n",
      "623/623 [==============================] - 1s 2ms/sample - loss: 0.9058 - val_loss: 3.6095\n",
      "Epoch 16/1000\n",
      "623/623 [==============================] - 0s 532us/sample - loss: 0.8721 - val_loss: 4.3929\n",
      "Epoch 17/1000\n",
      "623/623 [==============================] - 0s 577us/sample - loss: 0.9910 - val_loss: 5.9317\n",
      "Epoch 18/1000\n",
      "623/623 [==============================] - 0s 455us/sample - loss: 0.9860 - val_loss: 3.7246\n",
      "Epoch 19/1000\n",
      "623/623 [==============================] - 0s 452us/sample - loss: 0.8749 - val_loss: 3.7234\n",
      "Epoch 20/1000\n",
      "623/623 [==============================] - 0s 451us/sample - loss: 0.9230 - val_loss: 4.3001\n",
      "Epoch 21/1000\n",
      "623/623 [==============================] - 0s 455us/sample - loss: 0.9024 - val_loss: 4.5506\n",
      "Epoch 22/1000\n",
      "623/623 [==============================] - 0s 453us/sample - loss: 0.8663 - val_loss: 3.7110\n",
      "Epoch 23/1000\n",
      "623/623 [==============================] - 0s 449us/sample - loss: 0.8483 - val_loss: 3.6785\n",
      "Epoch 24/1000\n",
      "623/623 [==============================] - 0s 464us/sample - loss: 0.8363 - val_loss: 4.6239\n",
      "Epoch 25/1000\n",
      "623/623 [==============================] - 0s 457us/sample - loss: 0.8779 - val_loss: 3.5376\n",
      "Epoch 26/1000\n",
      "623/623 [==============================] - 0s 453us/sample - loss: 0.8429 - val_loss: 3.7565\n",
      "Epoch 27/1000\n",
      "623/623 [==============================] - 0s 464us/sample - loss: 0.8650 - val_loss: 3.4979\n",
      "Epoch 28/1000\n",
      "623/623 [==============================] - 0s 455us/sample - loss: 0.8809 - val_loss: 5.4724\n",
      "Epoch 29/1000\n",
      "623/623 [==============================] - 0s 534us/sample - loss: 0.8599 - val_loss: 3.4704\n",
      "Epoch 30/1000\n",
      "623/623 [==============================] - 0s 581us/sample - loss: 0.9647 - val_loss: 4.6004\n",
      "Epoch 31/1000\n",
      "623/623 [==============================] - 0s 582us/sample - loss: 1.0578 - val_loss: 4.5723\n",
      "Epoch 32/1000\n",
      "623/623 [==============================] - 0s 528us/sample - loss: 0.8766 - val_loss: 4.5318\n",
      "Epoch 33/1000\n",
      "623/623 [==============================] - 0s 479us/sample - loss: 0.9307 - val_loss: 3.3575\n",
      "Epoch 34/1000\n",
      "623/623 [==============================] - 0s 455us/sample - loss: 0.9442 - val_loss: 3.4347\n",
      "Epoch 35/1000\n",
      "623/623 [==============================] - 0s 469us/sample - loss: 0.9259 - val_loss: 7.3977\n",
      "Epoch 36/1000\n",
      "623/623 [==============================] - 0s 458us/sample - loss: 0.9496 - val_loss: 3.7577\n",
      "Epoch 37/1000\n",
      "623/623 [==============================] - 0s 455us/sample - loss: 0.8447 - val_loss: 3.5199\n",
      "Epoch 00037: early stopping\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "models = {\n",
    "#     'svmReg':svm.SVR(kernel='linear').fit(X_train, y_train),\n",
    "#     'gboost':GradientBoostingRegressor(loss='ls', random_state=SEED).fit(X_train, y_train),\n",
    "#     'dtReg':tree.DecisionTreeRegressor(random_state=SEED).fit(X_train, y_train),\n",
    "    'dnn':fit_ann()\n",
    "}\n",
    "# ensReg = VotingRegressor(estimators=models.items()).fit(X_train, y_train)\n",
    "# models.update({'ensReg':ensReg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn</th>\n",
       "      <th>todays_price</th>\n",
       "      <th>future_actual</th>\n",
       "      <th>actual_signal</th>\n",
       "      <th>dnn_pred_signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>[186.21057]</td>\n",
       "      <td>186.809448</td>\n",
       "      <td>187.298752</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>[186.67055]</td>\n",
       "      <td>187.298752</td>\n",
       "      <td>188.886444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>[188.29851]</td>\n",
       "      <td>188.886444</td>\n",
       "      <td>189.116104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>[188.48889]</td>\n",
       "      <td>189.116104</td>\n",
       "      <td>187.558365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>[186.93298]</td>\n",
       "      <td>187.558365</td>\n",
       "      <td>187.628250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dnn  todays_price  future_actual  actual_signal  dnn_pred_signal\n",
       "Date                                                                                \n",
       "2019-12-23  [186.21057]    186.809448     187.298752              1                0\n",
       "2019-12-24  [186.67055]    187.298752     188.886444              1                0\n",
       "2019-12-26  [188.29851]    188.886444     189.116104              1                0\n",
       "2019-12-27  [188.48889]    189.116104     187.558365              0                0\n",
       "2019-12-30  [186.93298]    187.558365     187.628250              1                0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred. table\n",
    "pred_table = pd.DataFrame()\n",
    "for m in models.items():\n",
    "    pred_table[f\"future_pred_{m[0]}\"] = test_df.drop(f\"{TARGET}_Future\",axis=1).apply(predict_sample, args=(m[1],), axis=1) # predict rows\n",
    "\n",
    "pred_table = pd.concat([pred_table, processed_data[[f\"{TARGET}_price_[t]\", f\"{TARGET}_Future\"]]], axis=1) # concat today's & future's actuals\n",
    "new_names = list(models.keys())\n",
    "new_names.extend([\"todays_price\", \"future_actual\"])\n",
    "pred_table.columns = new_names # rename\n",
    "pred_table.dropna(inplace=True)\n",
    "pred_table[\"actual_signal\"] = pred_table.apply(lambda x: 1 if x[\"future_actual\"] >= x[\"todays_price\"] else 0, axis=1) # actual signal\n",
    "\n",
    "for m1 in models.keys():\n",
    "    pred_table[f\"{m1}_pred_signal\"] = pred_table.apply(lambda x: 1  if x[m1] >= x[\"todays_price\"] else 0, axis=1) # strategy signal\n",
    "\n",
    "pred_table.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnn_pred_signal\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.95      0.57       257\n",
      "           1       0.50      0.04      0.07       366\n",
      "\n",
      "    accuracy                           0.41       623\n",
      "   macro avg       0.45      0.49      0.32       623\n",
      "weighted avg       0.46      0.41      0.27       623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "for i in pred_table.columns:\n",
    "    if i.endswith(\"_pred_signal\"):\n",
    "        print(i)\n",
    "        print(classification_report(pred_table[\"actual_signal\"], pred_table[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dnn</th>\n",
       "      <th>todays_price</th>\n",
       "      <th>future_actual</th>\n",
       "      <th>actual_signal</th>\n",
       "      <th>pred_signal</th>\n",
       "      <th>P&amp;L</th>\n",
       "      <th>Cumulative_Profit</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>[186.21057]</td>\n",
       "      <td>186.809448</td>\n",
       "      <td>187.298752</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.804108</td>\n",
       "      <td>-4855.772057</td>\n",
       "      <td>5144.227943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>[186.67055]</td>\n",
       "      <td>187.298752</td>\n",
       "      <td>188.886444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-13.211197</td>\n",
       "      <td>-4868.983253</td>\n",
       "      <td>5131.016747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>[188.29851]</td>\n",
       "      <td>188.886444</td>\n",
       "      <td>189.116104</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-42.867691</td>\n",
       "      <td>-4911.850945</td>\n",
       "      <td>5088.149055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>[188.48889]</td>\n",
       "      <td>189.116104</td>\n",
       "      <td>187.558365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.971161</td>\n",
       "      <td>-4917.822105</td>\n",
       "      <td>5082.177895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>[186.93298]</td>\n",
       "      <td>187.558365</td>\n",
       "      <td>187.628250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.501221</td>\n",
       "      <td>-4877.320885</td>\n",
       "      <td>5122.679115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    dnn  todays_price  future_actual  actual_signal  pred_signal        P&L  Cumulative_Profit      Balance\n",
       "Date                                                                                                                       \n",
       "2019-12-23  [186.21057]    186.809448     187.298752              1            0  24.804108       -4855.772057  5144.227943\n",
       "2019-12-24  [186.67055]    187.298752     188.886444              1            0 -13.211197       -4868.983253  5131.016747\n",
       "2019-12-26  [188.29851]    188.886444     189.116104              1            0 -42.867691       -4911.850945  5088.149055\n",
       "2019-12-27  [188.48889]    189.116104     187.558365              0            0  -5.971161       -4917.822105  5082.177895\n",
       "2019-12-30  [186.93298]    187.558365     187.628250              1            0  40.501221       -4877.320885  5122.679115"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PREDICTOR = \"dnn\"\n",
    "trade_df = pred_table[[PREDICTOR, \"todays_price\", \"future_actual\", \"actual_signal\", f\"{PREDICTOR}_pred_signal\"]]\n",
    "trade_df.columns = [\"pred_signal\" if n.endswith(\"pred_signal\") else n for n in trade_df.columns] # rename last col.\n",
    "\n",
    "pos = None\n",
    "ALLOW_SHORTS = True\n",
    "BALANCE = 10000.00\n",
    "_balance = BALANCE\n",
    "first_iter = True\n",
    "\n",
    "trade_df[\"P&L\"] = trade_df.apply(return_profit, axis=1)\n",
    "trade_df[\"Cumulative_Profit\"] = trade_df[\"P&L\"].cumsum()\n",
    "trade_df['Balance'] = trade_df.apply(get_balance, axis=1)\n",
    "trade_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    597\n",
       "1     26\n",
       "Name: pred_signal, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_df[\"pred_signal\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search for best seq/per\n",
    "# # seq 5, per 1\n",
    "# results = []\n",
    "# for seq in tqdm(range(1,2)):\n",
    "#     for per in range(1,2):\n",
    "#         TARGET=\"AAPL\"\n",
    "#         SEQ_LEN=seq # previous data\n",
    "#         PERIOD=per # future data\n",
    "#         FEATURES_TYPE=\"since\"\n",
    "#         FORWARD_TEST = True\n",
    "#         SCALING = \"none\" # none / minmax / standard\n",
    "#         SPLIT_SIZE = 0.5 # training size\n",
    "\n",
    "#         processed_data = process_reg_data(target=TARGET, seq_len=SEQ_LEN, period=PERIOD, features_type=FEATURES_TYPE, df=DF)\n",
    "#         X_train, X_test, y_train, y_test, test_df = split_data(forward_test=FORWARD_TEST, scaling=SCALING, split_size=SPLIT_SIZE, proc_data=processed_data)\n",
    "\n",
    "#         # model\n",
    "#         svmReg = svm.SVR(kernel='linear').fit(X_train, y_train)\n",
    "\n",
    "#         # evaluation\n",
    "#         eval_df = pd.DataFrame()\n",
    "#         eval_df[f\"future_{TARGET}_prediction\"] = test_df.drop(f\"{TARGET}_Future\",axis=1).apply(predict_sample, args=(svmReg,), axis=1)\n",
    "#         eval_df = pd.concat([eval_df, processed_data[[f\"{TARGET}_price_[t]\", f\"{TARGET}_Future\"]]], axis=1)\n",
    "#         eval_df.columns = ['future_pred', \"todays_price\", \"future_actual\"]\n",
    "#         eval_df.dropna(inplace=True)\n",
    "#         eval_df[\"actual_signal\"] = eval_df.apply(lambda x: 1 if x[\"future_actual\"] >= x[\"todays_price\"] else 0, axis=1)\n",
    "#         eval_df[\"pred_signal\"] = eval_df.apply(lambda x: 1  if x[\"future_pred\"] >= x[\"todays_price\"] else 0, axis=1)\n",
    "        \n",
    "#         preds = eval_df[\"pred_signal\"]\n",
    "#         acts = eval_df[\"actual_signal\"]\n",
    "        \n",
    "#         res = {\"SEQ\":SEQ_LEN,\n",
    "#                \"PERIOD\":PERIOD,\n",
    "#                \"ACC\":accuracy_score(acts, preds),\n",
    "#                \"AUC\":roc_auc_score(acts, preds),\n",
    "#                \"PRECISION_0\":precision_recall_fscore_support(acts, preds)[0][0],\n",
    "#                \"PRECISION_1\":precision_recall_fscore_support(acts, preds)[0][1]\n",
    "#               }\n",
    "        \n",
    "    \n",
    "#         try:\n",
    "#             zero = preds.value_counts()[0]\n",
    "#         except:\n",
    "#             zero = None\n",
    "        \n",
    "#         try:\n",
    "#             one = preds.value_counts()[1]\n",
    "#         except:\n",
    "#             one = None\n",
    "            \n",
    "#         res.update({\"zeros\":zero, \"ones\":one})\n",
    "        \n",
    "#         results.append(res)\n",
    "        \n",
    "\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv(f\"res_{int(time.time())}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "# svmClf = svm.SVC(kernel='rbf').fit(X_train, y_train)\n",
    "# svmClfPreds = svmClf.predict(X_test)\n",
    "# print(classification_report(y_test, svmClfPreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDDOTo3ZtH1e"
   },
   "outputs": [],
   "source": [
    "# # visualisations:\n",
    "# df = DF\n",
    "\n",
    "# # model vs actual plot\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=test_df.index,\n",
    "#     y=y_test,\n",
    "#     name=f\"Actual\",\n",
    "# #     line_color='#c761ff',\n",
    "#     line=dict(width=2, dash=\"solid\"),\n",
    "#     opacity=0.6\n",
    "#     )\n",
    "# )\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=test_df.index,\n",
    "#     y=svmPreds,\n",
    "#     name=f\"Predicted\",\n",
    "# #     line_color='#c761ff',\n",
    "#     line=dict(width=2, dash=\"dot\"),\n",
    "#     opacity=1\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=f\"{TARGET} Daily Chart<br>Actual vs Model's Prediction\",\n",
    "#     xaxis_title='Date',\n",
    "#     yaxis_title='Price ($)',\n",
    "# #     template=\"plotly_dark\",\n",
    "# )\n",
    "\n",
    "# fig.show()\n",
    "# ###\n",
    "\n",
    "\n",
    "\n",
    "# # correlation heatmap\n",
    "# # plt.figure(figsize=(15,7))\n",
    "# corr = df.corr()\n",
    "# mask = np.zeros_like(corr)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# with sns.axes_style(\"white\"):\n",
    "#     ax1 = sns.heatmap(corr, mask=mask, square=False,cmap=\"coolwarm\").set_title(\"Percent Change Correlation Heatmap\")       \n",
    "# ###\n",
    "\n",
    "\n",
    "\n",
    "# # distributions\n",
    "# fig = ff.create_distplot([df.pct_change().dropna()[c] for c in df.pct_change().columns], df.pct_change().columns, show_rug=False, show_hist=False)\n",
    "# fig.update_layout(\n",
    "#     title=f'Daily Return Distribution')\n",
    "# fig.show()\n",
    "# ###\n",
    "\n",
    "\n",
    "\n",
    "# # prices subplots\n",
    "# fig = make_subplots(rows=df.shape[1], cols=1, start_cell=\"bottom-left\",     subplot_titles=df.columns,shared_xaxes=True)\n",
    "\n",
    "# i, j = 1, 1\n",
    "# for col in df.columns:\n",
    "#     fig.add_trace(go.Scatter(x=df.index, y=df[col],name=col), row=i, col=1)\n",
    "#     i += 1\n",
    "# #     if j != 4: i += 1\n",
    "# #     else:\n",
    "# #         i += 1\n",
    "# #         j = 1\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=f' Daily Chart',\n",
    "#     xaxis_title='Date',\n",
    "#     yaxis_title='Price ($)',\n",
    "# #     xaxis=dict(position=1)\n",
    "# #     template=\"plotly_dark\",\n",
    "# )\n",
    "# fig.update_layout(\n",
    "#     autosize=True,\n",
    "# #      width=1500,\n",
    "#     height=2000,\n",
    "#     margin=dict(\n",
    "#         l=50,\n",
    "#         r=50,\n",
    "#         b=100,\n",
    "#         t=100,\n",
    "#         pad=4\n",
    "#     ),\n",
    "# #     paper_bgcolor=\"LightSteelBlue\",\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Stock_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
