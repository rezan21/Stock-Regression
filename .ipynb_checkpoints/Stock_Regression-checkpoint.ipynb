{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "zsAE77B4tH0V",
    "outputId": "2b1e360b-7947-4e42-dbff-2126c05f2c6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rezanaghshineh/opt/anaconda3/lib/python3.7/site-packages/pandas_datareader/compat/__init__.py:7: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_frame_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "sep = \"-*-*-\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # disable GPU\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "\n",
    "# visuals.\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# processing / validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# keras/tf\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "print(\"tensorflow version: \", tf.__version__)\n",
    "\n",
    "# models\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score # reg metrics\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_auc_score,\\\n",
    "accuracy_score, precision_score, average_precision_score, balanced_accuracy_score,\\\n",
    "precision_recall_fscore_support# clf metrics\n",
    "\n",
    "# constant seed for reproducibility\n",
    "SEED = 111 \n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# cpu workers\n",
    "WORKERS = 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opDdskO6tH0n"
   },
   "outputs": [],
   "source": [
    "def fetch_data_since(tickers, days, years):\n",
    "\n",
    "    df_raw = pd.DataFrame() \n",
    "    attempt = 0\n",
    "    drop = []\n",
    "    while len(tickers) != 0 and attempt <= 5:\n",
    "        tickers = [j for j in tickers if j not in drop] \n",
    "        for i in range(len(tickers)):\n",
    "            try:\n",
    "                temp = web.get_data_yahoo(tickers[i],\n",
    "                                          datetime.date.today() - datetime.timedelta(days * years), # since delta\n",
    "                                          datetime.date.today()) # until today \n",
    "\n",
    "                temp.dropna(inplace = True)\n",
    "                df_raw[tickers[i]] = temp[\"Adj Close\"]\n",
    "                drop.append(tickers[i])       \n",
    "            except:\n",
    "                print(tickers[i],\" :failed to fetch data...retrying\")\n",
    "                continue\n",
    "        attempt+=1\n",
    "       \n",
    "    # missing values\n",
    "    print(\"Missing Values:\")\n",
    "    print(df_raw.isnull().sum())\n",
    "    df = df_raw.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def fetch_data_from_to(tickers, _from, to):\n",
    "\n",
    "    df_raw = pd.DataFrame() \n",
    "    attempt = 0\n",
    "    drop = []\n",
    "    while len(tickers) != 0 and attempt <= 5:\n",
    "        tickers = [j for j in tickers if j not in drop] \n",
    "        for i in range(len(tickers)):\n",
    "            try:\n",
    "                temp = web.get_data_yahoo(tickers[i], _from, to ) # specified range\n",
    "\n",
    "                temp.dropna(inplace = True)\n",
    "                df_raw[tickers[i]] = temp[\"Adj Close\"]\n",
    "                drop.append(tickers[i])       \n",
    "            except:\n",
    "                print(tickers[i],\" :failed to fetch data...retrying\")\n",
    "                continue\n",
    "        attempt+=1\n",
    "       \n",
    "    # missing values\n",
    "    print(\"Missing Values:\")\n",
    "    print(df_raw.isnull().sum())\n",
    "    df = df_raw.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def process_clf_data(target, seq_len, period, features_type, df):\n",
    "    print(f\"\\n{sep*10}\\nClassification(!) Processing\\n{sep*10}\")\n",
    "    df_pct = pd.DataFrame() # blank dataframe\n",
    "\n",
    "\n",
    "    if features_type==\"since\": # changes since previous days\n",
    "        for col in df.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_snc_[t-{i}]\"] = df[col].pct_change(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    \n",
    "    elif features_type==\"shifted\": # shifted changes of previous days\n",
    "        for col in df.columns:\n",
    "#             if col != target: # without target's pct_change\n",
    "            df_pct[col] = df[col].pct_change(1)\n",
    "        df_pct.dropna(inplace=True)\n",
    "        \n",
    "        # shifted previous\n",
    "        for col in df_pct.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_sht_[t-{i}]\"] = df_pct[col].shift(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"features_type can be either 'since' or 'shifted'.\")\n",
    "\n",
    "\n",
    "    df_pct[f\"{target}_price_[t]\"] = df[target] # price [t]\n",
    "\n",
    "    # labeling\n",
    "    df_pct[f\"{target}_Future\"] = df[target].shift(-period) # future price [t + perid]\n",
    "    \n",
    "    warnings = 0\n",
    "    def classify(x):\n",
    "#         print(warnings)\n",
    "        if x[f\"{target}_Future\"] >= x[f\"{target}_price_[t]\"]:\n",
    "            return 1\n",
    "        elif x[f\"{target}_Future\"] < x[f\"{target}_price_[t]\"]:\n",
    "            return 0\n",
    "        else:\n",
    "            nonlocal warnings\n",
    "            warnings += 1\n",
    "            return None\n",
    "    \n",
    "    df_pct[f\"{target}_Future\"] = df_pct.apply(classify, axis=1) # classify\n",
    "\n",
    "\n",
    "    if warnings > 1:\n",
    "        raise ValueError(\"More than 1 NaN in classifying.\")\n",
    "        \n",
    "    \n",
    "    df_pct.dropna(inplace=True)\n",
    "    if df_pct.isnull().any().any():\n",
    "        raise ValueError(\"null values exist\")\n",
    "        \n",
    "    return df_pct\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def process_reg_data(target, seq_len, period, features_type, df):\n",
    "    print(f\"\\n{sep*10}\\nRegression Processing\\n{sep*10}\")\n",
    "    df_pct = pd.DataFrame() # blank dataframe\n",
    "\n",
    "\n",
    "    if features_type==\"since\": # changes since previous days\n",
    "        for col in df.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_snc_[t-{i}]\"] = df[col].pct_change(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    \n",
    "    elif features_type==\"shifted\": # shifted changes of previous days\n",
    "        for col in df.columns:\n",
    "#             if col != target: # without target's pct_change\n",
    "            df_pct[col] = df[col].pct_change(1)\n",
    "        df_pct.dropna(inplace=True)\n",
    "        \n",
    "        # shifted previous\n",
    "        for col in df_pct.columns:\n",
    "            for i in range(1,seq_len+1):\n",
    "                df_pct[f\"{col}_sht_[t-{i}]\"] = df_pct[col].shift(i)\n",
    "        df_pct.dropna(inplace=True)\n",
    "    else:\n",
    "        raise ValueError(\"features_type can be either 'since' or 'shifted'.\")\n",
    "\n",
    "\n",
    "    df_pct[f\"{target}_price_[t]\"] = df[target] # target's price\n",
    "\n",
    "    # labeling\n",
    "    df_pct[f\"{target}_Future\"] = df[target].shift(-period)\n",
    "\n",
    "    df_pct.dropna(inplace=True)\n",
    "    if df_pct.isnull().any().any():\n",
    "        raise ValueError(\"null values exist\")\n",
    "        \n",
    "    return df_pct\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def split_data(forward_test, scaling, split_size, proc_data):\n",
    "    \n",
    "    # train/test & faeture/label split\n",
    "    if forward_test==True:\n",
    "    #     forward test (recommended)\n",
    "        nth_prcntile = int(len(proc_data)*split_size)\n",
    "        test_df = proc_data.iloc[nth_prcntile:,:]\n",
    "        \n",
    "        train_df = proc_data.drop(test_df.index)\n",
    "        train_df = train_df.sample(frac=1, random_state=SEED) # shuffle train dataset\n",
    "\n",
    "        # features\n",
    "        X_train = train_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "        X_test = test_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "\n",
    "        # labels\n",
    "        y_train = train_df[f\"{TARGET}_Future\"].values\n",
    "        y_test = test_df[f\"{TARGET}_Future\"].values\n",
    "        \n",
    "    elif forward_test==False:\n",
    "        proc_data = proc_data.sample(frac=(1), random_state=SEED) # shuffle all data\n",
    "        test_df = proc_data.sample(frac=(1-split_size), random_state=SEED) # sample test dataset\n",
    "        train_df = proc_data.drop(test_df.index)\n",
    "\n",
    "        # features\n",
    "        X_train = train_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "        X_test = test_df.drop(f\"{TARGET}_Future\", axis=1).values\n",
    "\n",
    "        # labels\n",
    "        y_train = train_df[f\"{TARGET}_Future\"].values\n",
    "        y_test = test_df[f\"{TARGET}_Future\"].values\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"forward_test must be boolean.\")\n",
    "\n",
    "\n",
    "    # scaling\n",
    "    if scaling==\"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        x_test_df = pd.DataFrame(X_test, columns=proc_data.drop(f\"{TARGET}_Future\", axis=1).columns, index=test_df.index)\n",
    "        y_test_df = pd.DataFrame(y_test, columns=[f\"{TARGET}_Future\"], index=test_df.index)\n",
    "        test_df = pd.concat([x_test_df, y_test_df], axis=1)\n",
    "        \n",
    "    elif scaling==\"standard\":\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        x_test_df = pd.DataFrame(X_test, columns=proc_data.drop(f\"{TARGET}_Future\", axis=1).columns, index=test_df.index)\n",
    "        y_test_df = pd.DataFrame(y_test, columns=[f\"{TARGET}_Future\"], index=test_df.index)\n",
    "        test_df = pd.concat([x_test_df, y_test_df], axis=1)\n",
    "        \n",
    "    elif scaling==\"none\":\n",
    "        pass\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"scaling can be either 'minmax', 'standard' or 'none'.\")\n",
    "    \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, test_df\n",
    "\n",
    "###################################################################################################################\n",
    "\n",
    "def predict_sample(features_serie, model):\n",
    "    features = np.array(features_serie).reshape(1,-1)\n",
    "    pred = model.predict(features)[0]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 552
    },
    "colab_type": "code",
    "id": "4jatVTodtH0w",
    "outputId": "a120d5ab-ea34-4876-adf5-3064ce1b431d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "MSFT    0\n",
      "AAPL    0\n",
      "AMZN    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>37.393559</td>\n",
       "      <td>3.470226</td>\n",
       "      <td>89.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>36.130390</td>\n",
       "      <td>3.177650</td>\n",
       "      <td>81.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>36.511333</td>\n",
       "      <td>3.224152</td>\n",
       "      <td>69.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>35.288280</td>\n",
       "      <td>2.945139</td>\n",
       "      <td>65.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>35.749432</td>\n",
       "      <td>3.084645</td>\n",
       "      <td>69.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>156.951309</td>\n",
       "      <td>283.596924</td>\n",
       "      <td>1789.209961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>158.237793</td>\n",
       "      <td>289.223602</td>\n",
       "      <td>1868.770020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>158.527008</td>\n",
       "      <td>289.113831</td>\n",
       "      <td>1869.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>157.160736</td>\n",
       "      <td>290.829773</td>\n",
       "      <td>1846.890015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>157.270432</td>\n",
       "      <td>292.954712</td>\n",
       "      <td>1847.839966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5031 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MSFT        AAPL         AMZN\n",
       "Date                                           \n",
       "2000-01-03   37.393559    3.470226    89.375000\n",
       "2000-01-04   36.130390    3.177650    81.937500\n",
       "2000-01-05   36.511333    3.224152    69.750000\n",
       "2000-01-06   35.288280    2.945139    65.562500\n",
       "2000-01-07   35.749432    3.084645    69.562500\n",
       "...                ...         ...          ...\n",
       "2019-12-24  156.951309  283.596924  1789.209961\n",
       "2019-12-26  158.237793  289.223602  1868.770020\n",
       "2019-12-27  158.527008  289.113831  1869.800049\n",
       "2019-12-30  157.160736  290.829773  1846.890015\n",
       "2019-12-31  157.270432  292.954712  1847.839966\n",
       "\n",
       "[5031 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TICKERS = [\"^DJI\", \"^GSPC\", \"MSFT\", \"AAPL\", \"AMZN\", \"GOOGL\", \"JPM\", \"JNJ\", \"V\", \"MA\", \"INTC\"]\n",
    "TICKERS = [\"MSFT\", \"AAPL\", \"AMZN\"]\n",
    "\n",
    "# DAYS = 365\n",
    "# YEARS = 3\n",
    "# DF = fetch_data_since(tickers=TICKERS, days=DAYS, years=YEARS)\n",
    "\n",
    "FROM = '2000'\n",
    "TO = '2020' # excld.\n",
    "DF = fetch_data_from_to(tickers=TICKERS, _from=FROM, to=TO)\n",
    "\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 776
    },
    "colab_type": "code",
    "id": "xFrHvXXvtH04",
    "outputId": "7ac0f28d-3b94-41c8-8507-718f5e42a9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*-\n",
      "Regression Processing\n",
      "-*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*--*-*-\n",
      "processed shape: (5024, 20)\n",
      "-*-*-\n",
      "test_df shape: (1508, 20)\n",
      "-*-*-\n",
      "features: train shape: (3516, 19) | test Shape: (1508, 19)\n",
      "-*-*-\n",
      "labels: train shape: (3516,) | test Shape: (1508,)\n",
      "-*-*-\n",
      "X_train Max/Min: 87.43832397460938 / -0.5186915122085852\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSFT</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>MSFT_sht_[t-1]</th>\n",
       "      <th>MSFT_sht_[t-2]</th>\n",
       "      <th>MSFT_sht_[t-3]</th>\n",
       "      <th>MSFT_sht_[t-4]</th>\n",
       "      <th>MSFT_sht_[t-5]</th>\n",
       "      <th>AAPL_sht_[t-1]</th>\n",
       "      <th>AAPL_sht_[t-2]</th>\n",
       "      <th>AAPL_sht_[t-3]</th>\n",
       "      <th>AAPL_sht_[t-4]</th>\n",
       "      <th>AAPL_sht_[t-5]</th>\n",
       "      <th>AMZN_sht_[t-1]</th>\n",
       "      <th>AMZN_sht_[t-2]</th>\n",
       "      <th>AMZN_sht_[t-3]</th>\n",
       "      <th>AMZN_sht_[t-4]</th>\n",
       "      <th>AMZN_sht_[t-5]</th>\n",
       "      <th>AAPL_price_[t]</th>\n",
       "      <th>AAPL_Future</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>-0.006728</td>\n",
       "      <td>-0.021966</td>\n",
       "      <td>-0.003845</td>\n",
       "      <td>-0.006682</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>0.009708</td>\n",
       "      <td>-0.014064</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.009944</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>-0.006641</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>-0.011832</td>\n",
       "      <td>-0.015604</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>69.380615</td>\n",
       "      <td>69.758965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>-0.021132</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>-0.007088</td>\n",
       "      <td>-0.006728</td>\n",
       "      <td>-0.006682</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004006</td>\n",
       "      <td>-0.021966</td>\n",
       "      <td>-0.014064</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.009944</td>\n",
       "      <td>-0.006757</td>\n",
       "      <td>-0.003845</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>-0.011832</td>\n",
       "      <td>-0.015604</td>\n",
       "      <td>69.758965</td>\n",
       "      <td>69.260056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-07</th>\n",
       "      <td>0.007750</td>\n",
       "      <td>-0.007152</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>-0.021132</td>\n",
       "      <td>-0.006728</td>\n",
       "      <td>-0.006682</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>-0.021966</td>\n",
       "      <td>-0.014064</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>-0.009944</td>\n",
       "      <td>-0.007088</td>\n",
       "      <td>-0.003845</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>-0.011832</td>\n",
       "      <td>69.260056</td>\n",
       "      <td>69.698692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-08</th>\n",
       "      <td>-0.017852</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>0.009773</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>-0.021132</td>\n",
       "      <td>-0.006728</td>\n",
       "      <td>-0.006682</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>-0.007152</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>-0.021966</td>\n",
       "      <td>-0.014064</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>-0.007088</td>\n",
       "      <td>-0.003845</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>0.013778</td>\n",
       "      <td>69.698692</td>\n",
       "      <td>68.808632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-09</th>\n",
       "      <td>-0.006432</td>\n",
       "      <td>-0.012770</td>\n",
       "      <td>-0.002264</td>\n",
       "      <td>-0.017852</td>\n",
       "      <td>0.007750</td>\n",
       "      <td>-0.021132</td>\n",
       "      <td>-0.006728</td>\n",
       "      <td>-0.006682</td>\n",
       "      <td>0.006333</td>\n",
       "      <td>-0.007152</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>-0.021966</td>\n",
       "      <td>-0.014064</td>\n",
       "      <td>0.009773</td>\n",
       "      <td>0.011178</td>\n",
       "      <td>-0.007088</td>\n",
       "      <td>-0.003845</td>\n",
       "      <td>-0.002056</td>\n",
       "      <td>68.808632</td>\n",
       "      <td>68.349464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>0.006471</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.017118</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>283.327576</td>\n",
       "      <td>283.596924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>-0.005401</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>0.012124</td>\n",
       "      <td>283.596924</td>\n",
       "      <td>289.223602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>0.044467</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>-0.002069</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>-0.002389</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>-0.003703</td>\n",
       "      <td>289.223602</td>\n",
       "      <td>289.113831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>0.001828</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>0.008680</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.044467</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>289.113831</td>\n",
       "      <td>290.829773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>-0.008619</td>\n",
       "      <td>0.005935</td>\n",
       "      <td>-0.012253</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010918</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.019840</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.044467</td>\n",
       "      <td>-0.002114</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>-0.003225</td>\n",
       "      <td>290.829773</td>\n",
       "      <td>292.954712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1508 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                MSFT      AAPL      AMZN  MSFT_sht_[t-1]  MSFT_sht_[t-2]  MSFT_sht_[t-3]  MSFT_sht_[t-4]  MSFT_sht_[t-5]  AAPL_sht_[t-1]  AAPL_sht_[t-2]  AAPL_sht_[t-3]  AAPL_sht_[t-4]  AAPL_sht_[t-5]  AMZN_sht_[t-1]  AMZN_sht_[t-2]  AMZN_sht_[t-3]  AMZN_sht_[t-4]  AMZN_sht_[t-5]  AAPL_price_[t]  AAPL_Future\n",
       "Date                                                                                                                                                                                                                                                                                                                 \n",
       "2014-01-03 -0.006728 -0.021966 -0.003845       -0.006682        0.003217        0.000000       -0.004006        0.009708       -0.014064        0.011722       -0.009944       -0.006757       -0.006641       -0.002056        0.013778       -0.011832       -0.015604        0.013001       69.380615    69.758965\n",
       "2014-01-06 -0.021132  0.005453 -0.007088       -0.006728       -0.006682        0.003217        0.000000       -0.004006       -0.021966       -0.014064        0.011722       -0.009944       -0.006757       -0.003845       -0.002056        0.013778       -0.011832       -0.015604       69.758965    69.260056\n",
       "2014-01-07  0.007750 -0.007152  0.011178       -0.021132       -0.006728       -0.006682        0.003217        0.000000        0.005453       -0.021966       -0.014064        0.011722       -0.009944       -0.007088       -0.003845       -0.002056        0.013778       -0.011832       69.260056    69.698692\n",
       "2014-01-08 -0.017852  0.006333  0.009773        0.007750       -0.021132       -0.006728       -0.006682        0.003217       -0.007152        0.005453       -0.021966       -0.014064        0.011722        0.011178       -0.007088       -0.003845       -0.002056        0.013778       69.698692    68.808632\n",
       "2014-01-09 -0.006432 -0.012770 -0.002264       -0.017852        0.007750       -0.021132       -0.006728       -0.006682        0.006333       -0.007152        0.005453       -0.021966       -0.014064        0.009773        0.011178       -0.007088       -0.003845       -0.002056       68.808632    68.349464\n",
       "...              ...       ...       ...             ...             ...             ...             ...             ...             ...             ...             ...             ...             ...             ...             ...             ...             ...             ...             ...          ...\n",
       "2019-12-23  0.000000  0.016318  0.003638        0.010918        0.008680       -0.002069       -0.005401        0.006471       -0.002071        0.001001       -0.002389        0.001965        0.017118       -0.003225        0.004624       -0.003703        0.012124        0.004696      283.327576   283.596924\n",
       "2019-12-24 -0.000191  0.000951 -0.002114        0.000000        0.010918        0.008680       -0.002069       -0.005401        0.016318       -0.002071        0.001001       -0.002389        0.001965        0.003638       -0.003225        0.004624       -0.003703        0.012124      283.596924   289.223602\n",
       "2019-12-26  0.008197  0.019840  0.044467       -0.000191        0.000000        0.010918        0.008680       -0.002069        0.000951        0.016318       -0.002071        0.001001       -0.002389       -0.002114        0.003638       -0.003225        0.004624       -0.003703      289.223602   289.113831\n",
       "2019-12-27  0.001828 -0.000380  0.000551        0.008197       -0.000191        0.000000        0.010918        0.008680        0.019840        0.000951        0.016318       -0.002071        0.001001        0.044467       -0.002114        0.003638       -0.003225        0.004624      289.113831   290.829773\n",
       "2019-12-30 -0.008619  0.005935 -0.012253        0.001828        0.008197       -0.000191        0.000000        0.010918       -0.000380        0.019840        0.000951        0.016318       -0.002071        0.000551        0.044467       -0.002114        0.003638       -0.003225      290.829773   292.954712\n",
       "\n",
       "[1508 rows x 20 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data prep.\n",
    "TARGET=\"AAPL\"\n",
    "SEQ_LEN=5 # previous data\n",
    "PERIOD=1 # future data\n",
    "FEATURES_TYPE=\"shifted\"\n",
    "FORWARD_TEST = True\n",
    "SCALING = \"none\" # none / minmax / standard\n",
    "SPLIT_SIZE = 0.7 # training size\n",
    "\n",
    "processed_data = process_reg_data(target=TARGET, seq_len=SEQ_LEN, period=PERIOD, features_type=FEATURES_TYPE, df=DF)\n",
    "X_train, X_test, y_train, y_test, test_df = split_data(forward_test=FORWARD_TEST, scaling=SCALING, split_size=SPLIT_SIZE, proc_data=processed_data)\n",
    "\n",
    "print(f\"processed shape: {processed_data.shape}\", end=f\"\\n{sep}\\n\")\n",
    "print(f\"test_df shape: {test_df.shape}\", end=f\"\\n{sep}\\n\")\n",
    "print(f\"features: train shape: {X_train.shape} | test Shape: {X_test.shape}\", end=f\"\\n{sep}\\n\")\n",
    "print(f\"labels: train shape: {y_train.shape} | test Shape: {y_test.shape}\", end=f\"\\n{sep}\\n\")\n",
    "print(f\"X_train Max/Min: {X_train.max()} / {X_train.min()}\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "models = {'svmReg':svm.SVR(kernel='linear').fit(X_train, y_train),\n",
    "          'gboost':GradientBoostingRegressor(loss='ls', random_state=SEED).fit(X_train, y_train),\n",
    "          'dtReg':tree.DecisionTreeRegressor(random_state=SEED).fit(X_train, y_train)\n",
    "         }\n",
    "ensReg = VotingRegressor(estimators=models.items()).fit(X_train, y_train)\n",
    "models.update({'ensReg':ensReg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svmReg</th>\n",
       "      <th>gboost</th>\n",
       "      <th>dtReg</th>\n",
       "      <th>ensReg</th>\n",
       "      <th>todays_price</th>\n",
       "      <th>future_actual</th>\n",
       "      <th>actual_signal</th>\n",
       "      <th>svmReg_pred_signal</th>\n",
       "      <th>gboost_pred_signal</th>\n",
       "      <th>dtReg_pred_signal</th>\n",
       "      <th>ensReg_pred_signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>69.404204</td>\n",
       "      <td>70.411419</td>\n",
       "      <td>71.447174</td>\n",
       "      <td>70.420932</td>\n",
       "      <td>69.380615</td>\n",
       "      <td>69.758965</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>69.786297</td>\n",
       "      <td>70.756005</td>\n",
       "      <td>69.727234</td>\n",
       "      <td>70.089845</td>\n",
       "      <td>69.758965</td>\n",
       "      <td>69.260056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-07</th>\n",
       "      <td>69.281755</td>\n",
       "      <td>69.459602</td>\n",
       "      <td>67.820526</td>\n",
       "      <td>68.853961</td>\n",
       "      <td>69.260056</td>\n",
       "      <td>69.698692</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-08</th>\n",
       "      <td>69.707896</td>\n",
       "      <td>70.524119</td>\n",
       "      <td>71.177399</td>\n",
       "      <td>70.469805</td>\n",
       "      <td>69.698692</td>\n",
       "      <td>68.808632</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-09</th>\n",
       "      <td>68.835315</td>\n",
       "      <td>68.291336</td>\n",
       "      <td>67.820526</td>\n",
       "      <td>68.315726</td>\n",
       "      <td>68.808632</td>\n",
       "      <td>68.349464</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-23</th>\n",
       "      <td>283.381396</td>\n",
       "      <td>87.039909</td>\n",
       "      <td>87.149361</td>\n",
       "      <td>152.523555</td>\n",
       "      <td>283.327576</td>\n",
       "      <td>283.596924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>283.657725</td>\n",
       "      <td>86.872274</td>\n",
       "      <td>87.014877</td>\n",
       "      <td>152.514959</td>\n",
       "      <td>283.596924</td>\n",
       "      <td>289.223602</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>289.288338</td>\n",
       "      <td>86.988578</td>\n",
       "      <td>87.438324</td>\n",
       "      <td>154.571747</td>\n",
       "      <td>289.223602</td>\n",
       "      <td>289.113831</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>289.177153</td>\n",
       "      <td>86.400226</td>\n",
       "      <td>86.029793</td>\n",
       "      <td>153.869057</td>\n",
       "      <td>289.113831</td>\n",
       "      <td>290.829773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>290.884560</td>\n",
       "      <td>86.099885</td>\n",
       "      <td>86.029793</td>\n",
       "      <td>154.338079</td>\n",
       "      <td>290.829773</td>\n",
       "      <td>292.954712</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1508 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                svmReg     gboost      dtReg      ensReg  todays_price  future_actual  actual_signal  svmReg_pred_signal  gboost_pred_signal  dtReg_pred_signal  ensReg_pred_signal\n",
       "Date                                                                                                                                                                               \n",
       "2014-01-03   69.404204  70.411419  71.447174   70.420932     69.380615      69.758965              1                   1                   1                  1                   1\n",
       "2014-01-06   69.786297  70.756005  69.727234   70.089845     69.758965      69.260056              0                   1                   1                  0                   1\n",
       "2014-01-07   69.281755  69.459602  67.820526   68.853961     69.260056      69.698692              1                   1                   1                  0                   0\n",
       "2014-01-08   69.707896  70.524119  71.177399   70.469805     69.698692      68.808632              0                   1                   1                  1                   1\n",
       "2014-01-09   68.835315  68.291336  67.820526   68.315726     68.808632      68.349464              0                   1                   0                  0                   0\n",
       "...                ...        ...        ...         ...           ...            ...            ...                 ...                 ...                ...                 ...\n",
       "2019-12-23  283.381396  87.039909  87.149361  152.523555    283.327576     283.596924              1                   1                   0                  0                   0\n",
       "2019-12-24  283.657725  86.872274  87.014877  152.514959    283.596924     289.223602              1                   1                   0                  0                   0\n",
       "2019-12-26  289.288338  86.988578  87.438324  154.571747    289.223602     289.113831              0                   1                   0                  0                   0\n",
       "2019-12-27  289.177153  86.400226  86.029793  153.869057    289.113831     290.829773              1                   1                   0                  0                   0\n",
       "2019-12-30  290.884560  86.099885  86.029793  154.338079    290.829773     292.954712              1                   1                   0                  0                   0\n",
       "\n",
       "[1508 rows x 11 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pred. table\n",
    "pred_table = pd.DataFrame()\n",
    "for m in models.items():\n",
    "    pred_table[f\"future_pred_{m[0]}\"] = test_df.drop(f\"{TARGET}_Future\",axis=1).apply(predict_sample, args=(m[1],), axis=1) # predict rows\n",
    "\n",
    "pred_table = pd.concat([pred_table, processed_data[[f\"{TARGET}_price_[t]\", f\"{TARGET}_Future\"]]], axis=1) # concat today's & future's actuals\n",
    "new_names = list(models.keys())\n",
    "new_names.extend([\"todays_price\", \"future_actual\"])\n",
    "pred_table.columns = new_names # rename\n",
    "pred_table.dropna(inplace=True)\n",
    "pred_table[\"actual_signal\"] = pred_table.apply(lambda x: 1 if x[\"future_actual\"] >= x[\"todays_price\"] else 0, axis=1) # actual signal\n",
    "\n",
    "for m1 in models.keys():\n",
    "    pred_table[f\"{m1}_pred_signal\"] = pred_table.apply(lambda x: 1  if x[m1] >= x[\"todays_price\"] else 0, axis=1) # strategy signal\n",
    "\n",
    "pred_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svmReg_pred_signal\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.01      0.01       701\n",
      "           1       0.54      0.99      0.70       807\n",
      "\n",
      "    accuracy                           0.53      1508\n",
      "   macro avg       0.49      0.50      0.35      1508\n",
      "weighted avg       0.50      0.53      0.38      1508\n",
      "\n",
      "gboost_pred_signal\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.95      0.63       701\n",
      "           1       0.57      0.05      0.10       807\n",
      "\n",
      "    accuracy                           0.47      1508\n",
      "   macro avg       0.52      0.50      0.36      1508\n",
      "weighted avg       0.52      0.47      0.34      1508\n",
      "\n",
      "dtReg_pred_signal\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.95      0.63       701\n",
      "           1       0.61      0.06      0.12       807\n",
      "\n",
      "    accuracy                           0.48      1508\n",
      "   macro avg       0.54      0.51      0.37      1508\n",
      "weighted avg       0.55      0.48      0.35      1508\n",
      "\n",
      "ensReg_pred_signal\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.95      0.63       701\n",
      "           1       0.58      0.06      0.11       807\n",
      "\n",
      "    accuracy                           0.47      1508\n",
      "   macro avg       0.52      0.50      0.37      1508\n",
      "weighted avg       0.53      0.47      0.35      1508\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in pred_table.columns:\n",
    "    if i.endswith(\"_pred_signal\"):\n",
    "        print(i)\n",
    "        print(classification_report(pred_table[\"actual_signal\"], pred_table[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # grid search for best seq/per\n",
    "# # seq 5, per 1\n",
    "# results = []\n",
    "# for seq in tqdm(range(1,2)):\n",
    "#     for per in range(1,2):\n",
    "#         TARGET=\"AAPL\"\n",
    "#         SEQ_LEN=seq # previous data\n",
    "#         PERIOD=per # future data\n",
    "#         FEATURES_TYPE=\"since\"\n",
    "#         FORWARD_TEST = True\n",
    "#         SCALING = \"none\" # none / minmax / standard\n",
    "#         SPLIT_SIZE = 0.5 # training size\n",
    "\n",
    "#         processed_data = process_reg_data(target=TARGET, seq_len=SEQ_LEN, period=PERIOD, features_type=FEATURES_TYPE, df=DF)\n",
    "#         X_train, X_test, y_train, y_test, test_df = split_data(forward_test=FORWARD_TEST, scaling=SCALING, split_size=SPLIT_SIZE, proc_data=processed_data)\n",
    "\n",
    "#         # model\n",
    "#         svmReg = svm.SVR(kernel='linear').fit(X_train, y_train)\n",
    "\n",
    "#         # evaluation\n",
    "#         eval_df = pd.DataFrame()\n",
    "#         eval_df[f\"future_{TARGET}_prediction\"] = test_df.drop(f\"{TARGET}_Future\",axis=1).apply(predict_sample, args=(svmReg,), axis=1)\n",
    "#         eval_df = pd.concat([eval_df, processed_data[[f\"{TARGET}_price_[t]\", f\"{TARGET}_Future\"]]], axis=1)\n",
    "#         eval_df.columns = ['future_pred', \"todays_price\", \"future_actual\"]\n",
    "#         eval_df.dropna(inplace=True)\n",
    "#         eval_df[\"actual_signal\"] = eval_df.apply(lambda x: 1 if x[\"future_actual\"] >= x[\"todays_price\"] else 0, axis=1)\n",
    "#         eval_df[\"pred_signal\"] = eval_df.apply(lambda x: 1  if x[\"future_pred\"] >= x[\"todays_price\"] else 0, axis=1)\n",
    "        \n",
    "#         preds = eval_df[\"pred_signal\"]\n",
    "#         acts = eval_df[\"actual_signal\"]\n",
    "        \n",
    "#         res = {\"SEQ\":SEQ_LEN,\n",
    "#                \"PERIOD\":PERIOD,\n",
    "#                \"ACC\":accuracy_score(acts, preds),\n",
    "#                \"AUC\":roc_auc_score(acts, preds),\n",
    "#                \"PRECISION_0\":precision_recall_fscore_support(acts, preds)[0][0],\n",
    "#                \"PRECISION_1\":precision_recall_fscore_support(acts, preds)[0][1]\n",
    "#               }\n",
    "        \n",
    "    \n",
    "#         try:\n",
    "#             zero = preds.value_counts()[0]\n",
    "#         except:\n",
    "#             zero = None\n",
    "        \n",
    "#         try:\n",
    "#             one = preds.value_counts()[1]\n",
    "#         except:\n",
    "#             one = None\n",
    "            \n",
    "#         res.update({\"zeros\":zero, \"ones\":one})\n",
    "        \n",
    "#         results.append(res)\n",
    "        \n",
    "\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "# results_df.to_csv(f\"res_{int(time.time())}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification\n",
    "# svmClf = svm.SVC(kernel='rbf').fit(X_train, y_train)\n",
    "# svmClfPreds = svmClf.predict(X_test)\n",
    "# print(classification_report(y_test, svmClfPreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "U-SkT913tH09",
    "outputId": "dbf888cd-9b0f-4f04-b6e9-39707a6dbf33",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tf neural\n",
    "# def fit_ann():\n",
    "#     dnnReg = Sequential()\n",
    "\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "#     dnnReg.add(Dense(100, activation=\"relu\"))\n",
    "\n",
    "#     dnnReg.add(Dense(1))\n",
    "\n",
    "#     dnnReg.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "#     early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=PATIENCE)\n",
    "\n",
    "#     dnnReg.fit(x=X_train, y=y_train, epochs=1000,validation_data=(X_test,y_test),use_multiprocessing=True, workers=WORKERS, callbacks=[early_stop])\n",
    "#     return dnnReg\n",
    "\n",
    "# if False:\n",
    "#     dnnReg = fit_ann()\n",
    "#     pd.DataFrame(dnnReg.history.history).plot()\n",
    "#     dnnPreds = dnnReg.predict(X_test)\n",
    "#     print(sep*5)\n",
    "#     print(mean_squared_error(y_test, dnnPreds))\n",
    "#     print(r2_score(y_test, dnnPreds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SDDOTo3ZtH1e"
   },
   "outputs": [],
   "source": [
    "# # visualisations:\n",
    "# df = DF\n",
    "\n",
    "# # model vs actual plot\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=test_df.index,\n",
    "#     y=y_test,\n",
    "#     name=f\"Actual\",\n",
    "# #     line_color='#c761ff',\n",
    "#     line=dict(width=2, dash=\"solid\"),\n",
    "#     opacity=0.6\n",
    "#     )\n",
    "# )\n",
    "# fig.add_trace(go.Scatter(\n",
    "#     x=test_df.index,\n",
    "#     y=svmPreds,\n",
    "#     name=f\"Predicted\",\n",
    "# #     line_color='#c761ff',\n",
    "#     line=dict(width=2, dash=\"dot\"),\n",
    "#     opacity=1\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=f\"{TARGET} Daily Chart<br>Actual vs Model's Prediction\",\n",
    "#     xaxis_title='Date',\n",
    "#     yaxis_title='Price ($)',\n",
    "# #     template=\"plotly_dark\",\n",
    "# )\n",
    "\n",
    "# fig.show()\n",
    "# ###\n",
    "\n",
    "\n",
    "\n",
    "# # correlation heatmap\n",
    "# # plt.figure(figsize=(15,7))\n",
    "# corr = df.corr()\n",
    "# mask = np.zeros_like(corr)\n",
    "# mask[np.triu_indices_from(mask)] = True\n",
    "# with sns.axes_style(\"white\"):\n",
    "#     ax1 = sns.heatmap(corr, mask=mask, square=False,cmap=\"coolwarm\").set_title(\"Percent Change Correlation Heatmap\")       \n",
    "# ###\n",
    "\n",
    "\n",
    "\n",
    "# # distributions\n",
    "# fig = ff.create_distplot([df.pct_change().dropna()[c] for c in df.pct_change().columns], df.pct_change().columns, show_rug=False, show_hist=False)\n",
    "# fig.update_layout(\n",
    "#     title=f'Daily Return Distribution')\n",
    "# fig.show()\n",
    "# ###\n",
    "\n",
    "\n",
    "\n",
    "# # prices subplots\n",
    "# fig = make_subplots(rows=df.shape[1], cols=1, start_cell=\"bottom-left\",     subplot_titles=df.columns,shared_xaxes=True)\n",
    "\n",
    "# i, j = 1, 1\n",
    "# for col in df.columns:\n",
    "#     fig.add_trace(go.Scatter(x=df.index, y=df[col],name=col), row=i, col=1)\n",
    "#     i += 1\n",
    "# #     if j != 4: i += 1\n",
    "# #     else:\n",
    "# #         i += 1\n",
    "# #         j = 1\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=f' Daily Chart',\n",
    "#     xaxis_title='Date',\n",
    "#     yaxis_title='Price ($)',\n",
    "# #     xaxis=dict(position=1)\n",
    "# #     template=\"plotly_dark\",\n",
    "# )\n",
    "# fig.update_layout(\n",
    "#     autosize=True,\n",
    "# #      width=1500,\n",
    "#     height=2000,\n",
    "#     margin=dict(\n",
    "#         l=50,\n",
    "#         r=50,\n",
    "#         b=100,\n",
    "#         t=100,\n",
    "#         pad=4\n",
    "#     ),\n",
    "# #     paper_bgcolor=\"LightSteelBlue\",\n",
    "# )\n",
    "\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Stock_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
